{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lab 10 MNIST and softmax\n",
    "import torch\n",
    "import torchvision.datasets as dsets\n",
    "import torchvision.transforms as transforms\n",
    "import random\n",
    "\n",
    "import numpy as np\n",
    "import os\n",
    "import copy\n",
    "import datetime\n",
    "\n",
    "# torch.set_printoptions(profile=\"full\")\n",
    "# np.set_printoptions(threshold=np.inf)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "# for reproducibility\n",
    "random.seed(111)\n",
    "torch.manual_seed(777)\n",
    "if device == 'cuda':\n",
    "    torch.cuda.manual_seed_all(777)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# parameters\n",
    "learning_rate = 0.001\n",
    "training_epochs = 5\n",
    "batch_size = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MNIST dataset\n",
    "mnist_train = dsets.MNIST(root='MNIST_data/',\n",
    "                          train=True,\n",
    "                          transform=transforms.ToTensor(),\n",
    "                          download=True)\n",
    "\n",
    "mnist_test = dsets.MNIST(root='MNIST_data/',\n",
    "                         train=False,\n",
    "                         transform=transforms.ToTensor(),\n",
    "                         download=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataset loader\n",
    "data_loader = torch.utils.data.DataLoader(dataset=mnist_train,\n",
    "                                          batch_size=batch_size,\n",
    "                                          shuffle=True,\n",
    "                                          drop_last=True)\n",
    "test_loader = torch.utils.data.DataLoader(dataset=mnist_test,\n",
    "                                          batch_size=batch_size,\n",
    "                                          shuffle=True,\n",
    "                                          drop_last=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MyNet(\n",
      "  (layer1): Sequential(\n",
      "    (0): Conv2d(1, 25, kernel_size=(3, 3), stride=(1, 1))\n",
      "    (1): BatchNorm2d(25, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (2): ReLU(inplace=True)\n",
      "  )\n",
      "  (layer2): Sequential(\n",
      "    (0): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  )\n",
      "  (layer3): Sequential(\n",
      "    (0): Conv2d(25, 50, kernel_size=(3, 3), stride=(1, 1))\n",
      "    (1): BatchNorm2d(50, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (2): ReLU(inplace=True)\n",
      "  )\n",
      "  (layer4): Sequential(\n",
      "    (0): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  )\n",
      "  (fc): Sequential(\n",
      "    (0): Linear(in_features=1250, out_features=1024, bias=True)\n",
      "    (1): ReLU(inplace=True)\n",
      "    (2): Linear(in_features=1024, out_features=128, bias=True)\n",
      "    (3): ReLU(inplace=True)\n",
      "    (4): Linear(in_features=128, out_features=10, bias=True)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "class MyNet(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(MyNet, self).__init__()\n",
    "        self.layer1 = torch.nn.Sequential(\n",
    "            torch.nn.Conv2d(1, 25, kernel_size=3),\n",
    "            torch.nn.BatchNorm2d(25),\n",
    "            torch.nn.ReLU(inplace=True)\n",
    "        )\n",
    " \n",
    "        self.layer2 = torch.nn.Sequential(\n",
    "            torch.nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        )\n",
    " \n",
    "        self.layer3 = torch.nn.Sequential(\n",
    "            torch.nn.Conv2d(25, 50, kernel_size=3),\n",
    "            torch.nn.BatchNorm2d(50),\n",
    "            torch.nn.ReLU(inplace=True)\n",
    "        )\n",
    " \n",
    "        self.layer4 = torch.nn.Sequential(\n",
    "            torch.nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        )\n",
    " \n",
    "        self.fc = torch.nn.Sequential(\n",
    "            torch.nn.Linear(50 * 5 * 5, 1024),\n",
    "            torch.nn.ReLU(inplace=True),\n",
    "            torch.nn.Linear(1024, 128),\n",
    "            torch.nn.ReLU(inplace=True),\n",
    "            torch.nn.Linear(128, 10)\n",
    "        )\n",
    " \n",
    "    def forward(self, x):\n",
    "        x = self.layer1(x)\n",
    "        x = self.layer2(x)\n",
    "        x = self.layer3(x)\n",
    "        x = self.layer4(x)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = self.fc(x)\n",
    "        return x\n",
    "\n",
    "model = MyNet().to(device)\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define cost/loss & optimizer\n",
    "criterion = torch.nn.CrossEntropyLoss().to(device)    # Softmax is internally computed.\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['merge_attack0normal20_06-05--17-27-55.pth', 'merge_attack0normal20_06-05--17-28-09.pth', 'merge_attack0normal20_06-05--17-28-20.pth', 'merge_attack0normal20_06-05--17-28-32.pth', 'merge_attack0normal20_06-05--17-28-38.pth', 'merge_attack0normal20_06-05--17-29-32.pth', 'merge_attack0normal20_06-05--17-29-38.pth', 'merge_attack0normal20_06-05--17-29-40.pth', 'merge_attack0normal20_06-05--17-29-43.pth', 'merge_attack0normal20_06-05--17-29-46.pth', 'merge_attack0normal20_06-05--17-29-48.pth', 'merge_attack0normal20_06-05--17-29-51.pth', 'merge_attack0normal20_06-05--17-52-30.pth', 'merge_attack0normal20_06-05--17-52-34.pth', 'merge_attack0normal20_06-05--17-52-36.pth', 'merge_attack0normal20_06-05--17-52-39.pth', 'merge_attack0normal20_06-05--17-52-43.pth', 'merge_attack0normal20_06-05--17-52-45.pth', 'merge_attack0normal20_06-05--17-52-48.pth', 'merge_attack0normal20_06-05--17-52-52.pth', 'merge_attack0normal20_06-05--17-52-55.pth', 'merge_attack0normal20_06-05--17-52-57.pth', 'merge_attack0normal20_06-05--17-53-00.pth', 'merge_attack0normal20_06-05--17-53-02.pth', 'merge_attack0normal20_06-05--17-53-05.pth', 'merge_attack0normal20_06-05--17-53-07.pth', 'merge_attack0normal20_06-05--17-53-10.pth', 'merge_attack0normal20_06-05--17-53-12.pth', 'merge_attack0normal20_06-05--17-53-17.pth', 'merge_attack0normal20_06-05--17-53-49.pth', 'merge_attack1normal19_06-05--17-27-52.pth', 'merge_attack1normal19_06-05--17-28-05.pth', 'merge_attack1normal19_06-05--17-28-07.pth', 'merge_attack1normal19_06-05--17-28-14.pth', 'merge_attack1normal19_06-05--17-28-23.pth', 'merge_attack1normal19_06-05--17-28-27.pth', 'merge_attack1normal19_06-05--17-28-51.pth', 'merge_attack1normal19_06-05--17-53-41.pth', 'merge_attack1normal19_06-05--17-53-56.pth', 'merge_attack1normal19_06-05--17-54-00.pth', 'merge_attack2normal18_06-05--17-28-00.pth', 'merge_attack2normal18_06-05--17-28-12.pth', 'merge_attack2normal18_06-05--17-28-49.pth', 'merge_attack2normal18_06-05--17-53-39.pth', 'merge_attack2normal18_06-05--17-53-44.pth', 'merge_attack2normal18_06-05--17-53-46.pth', 'merge_attack3normal17_06-05--17-27-45.pth', 'merge_attack3normal17_06-05--17-27-58.pth', 'merge_attack3normal17_06-05--17-28-45.pth', 'merge_attack3normal17_06-05--17-53-58.pth', 'merge_attack4normal16_06-05--17-28-02.pth', 'merge_attack4normal16_06-05--17-28-25.pth', 'merge_attack4normal16_06-05--17-28-30.pth', 'merge_attack4normal16_06-05--17-28-34.pth', 'merge_attack4normal16_06-05--17-28-36.pth', 'merge_attack4normal16_06-05--17-28-47.pth', 'merge_attack4normal16_06-05--17-53-36.pth', 'merge_attack5normal15_06-05--17-28-18.pth', 'merge_attack5normal15_06-05--17-28-41.pth', 'merge_attack5normal15_06-05--17-28-42.pth', 'merge_attack5normal15_06-05--17-53-42.pth', 'merge_attack5normal15_06-05--17-53-47.pth', 'merge_attack5normal15_06-05--17-53-52.pth', 'merge_attack5normal15_06-05--17-53-54.pth']\n"
     ]
    }
   ],
   "source": [
    "# model.load_state_dict(torch.load(\"./myfed_normal_save/model18-32-05.pth\")[\"state_dict\"])\n",
    "dir = os.listdir(\"./merge_save\")\n",
    "modelnames = []\n",
    "for mt in dir:\n",
    "    if(mt[0:len(\"merge_attack\")] == \"merge_attack\"):\n",
    "        modelnames.append(mt)\n",
    "print(modelnames)\n",
    "modelset = []\n",
    "for mn in modelnames:\n",
    "    modelset.append([model.load_state_dict(torch.load(\"./merge_save/\"+mn)[\"state_dict\"]),mn])\n",
    "# print(dir)\n",
    "savepath = \"./metric/vr_metric=\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "for mode, modelname in modelset:\n",
    "    parm = {}\n",
    "    for name,parameters in model.named_parameters():\n",
    "        parm[name]=parameters\n",
    "        # print(parm[name])\n",
    "    tensors = []\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "\n",
    "        t=10\n",
    "        for i in range(0,t):\n",
    "            r = random.randint(0, (batch_size) - 1)\n",
    "\n",
    "            for X_test, Y_test in test_loader:\n",
    "                X_test = X_test.to(device)\n",
    "                Y_test = Y_test.to(device)\n",
    "            \n",
    "\n",
    "            X_single_data = X_test[r]\n",
    "            Y_single_data = Y_test[r]\n",
    "\n",
    "            # print(X_single_data)\n",
    "            \n",
    "            layerP = model.layer1(torch.unsqueeze(X_single_data,dim=0))\n",
    "            # print(\"1\",layerP)\n",
    "            layerP = model.layer2(layerP)\n",
    "            # print(\"2\",layerP)\n",
    "            layerP = model.layer3(layerP)\n",
    "            # print(\"3\",layerP)\n",
    "            layerP = model.layer4(layerP)\n",
    "            layerP = layerP.detach().squeeze().reshape(-1,1250)\n",
    "\n",
    "            tensor1 = torch.mm(layerP, parm['fc.0.weight'].data.permute(1,0)) + parm['fc.0.bias']\n",
    "            tensor1 = torch.mm(tensor1, parm['fc.2.weight'].data.permute(1,0)) + parm['fc.2.bias']\n",
    "            \n",
    "            tensors.append(tensor1.cpu().detach().numpy()[0])\n",
    "\n",
    "    nb = np.linspace(0,0,tensors[0].shape[0])\n",
    "    for i in tensors:\n",
    "        nb += i\n",
    "    nb /= t\n",
    "\n",
    "    ns = np.linspace(0,0,tensors[0].shape[0])\n",
    "    vp = np.linspace(0,0,tensors[0].shape[0] ** 2).reshape(tensors[0].shape[0],tensors[0].shape[0])\n",
    "\n",
    "    for i in range(0,len(ns)):\n",
    "        for nps in tensors:\n",
    "            ns[i] += nps[i] ** 2\n",
    "        ns[i] = ns[i] ** 0.5\n",
    "\n",
    "    for i in range(0,len(ns)):\n",
    "        for j in range(i+1,len(ns)):\n",
    "            for nps in tensors:\n",
    "                vp[i,j] += (nps[i] - nb[i]) * (nps[j] - nb[j])\n",
    "            vp[i,j] /= (ns[i] * ns[j])\n",
    "\n",
    "    dt = datetime.datetime.now()\n",
    "    # np.savetxt(\"./misc/vr_metric\"+dt.strftime(\"%d--%H-%M-%S\")+\".dat\", vp+vp.T, fmt=\"%1.5f\")\n",
    "    np.savetxt(savepath+modelname+dt.strftime(\"%m-%d--%H-%M-%S\")+\".dat\", vp+vp.T, fmt=\"%1.5f\")"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "61d7d72412218704c5ba1799d65c7a83b08e24a9ca7847de9a479f6f426633e7"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
