{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lab 10 MNIST and softmax\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import torch.optim as optim\n",
    "import torch.backends.cudnn as cudnn\n",
    "import time\n",
    "import random\n",
    "import datetime\n",
    "import os\n",
    "import sys\n",
    "\n",
    "import numpy as np\n",
    "import copy\n",
    "\n",
    "# torch.set_printoptions(profile=\"full\")\n",
    "# np.set_printoptions(threshold=np.inf)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "# for reproducibility\n",
    "random.seed(111)\n",
    "torch.manual_seed(777)\n",
    "if device == 'cuda':\n",
    "    torch.cuda.manual_seed_all(777)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# parameters\n",
    "learning_rate = 0.001\n",
    "training_epochs = 5\n",
    "batch_size = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.Compose(\n",
    "    [\n",
    "     transforms.RandomHorizontalFlip(),\n",
    "     transforms.RandomGrayscale(),\n",
    "     transforms.ToTensor(),\n",
    "     transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
    "\n",
    "transform1 = transforms.Compose(\n",
    "    [\n",
    "     transforms.ToTensor(),\n",
    "     transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
    "     \n",
    "transform_test = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "trainset = torchvision.datasets.CIFAR10(root='CIFAR10_data/', train=True,\n",
    "                                        download=True, transform=transform)\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=100,\n",
    "                                          shuffle=True, num_workers=2)\n",
    "\n",
    "testset = torchvision.datasets.CIFAR10(root='CIFAR10_data/', train=False,\n",
    "                                       download=True, transform=transform1)\n",
    "testloader = torch.utils.data.DataLoader(testset, batch_size=50,\n",
    "                                         shuffle=True, num_workers=2)\n",
    "\n",
    "classes = ('plane', 'car', 'bird', 'cat',\n",
    "           'deer', 'dog', 'frog', 'horse', 'ship', 'truck')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataParallel(\n",
      "  (module): Net(\n",
      "    (conv1): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (pool1): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu1): ReLU()\n",
      "    (conv3): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (conv4): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (pool2): MaxPool2d(kernel_size=2, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
      "    (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu2): ReLU()\n",
      "    (conv5): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (conv6): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (conv7): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), padding=(1, 1))\n",
      "    (pool3): MaxPool2d(kernel_size=2, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
      "    (bn3): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu3): ReLU()\n",
      "    (conv8): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (conv9): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (conv10): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1), padding=(1, 1))\n",
      "    (pool4): MaxPool2d(kernel_size=2, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
      "    (bn4): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu4): ReLU()\n",
      "    (conv11): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (conv12): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (conv13): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1), padding=(1, 1))\n",
      "    (pool5): MaxPool2d(kernel_size=2, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
      "    (bn5): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu5): ReLU()\n",
      "    (fc14): Linear(in_features=8192, out_features=1024, bias=True)\n",
      "    (drop1): Dropout2d(p=0.5, inplace=False)\n",
      "    (fc15): Linear(in_features=1024, out_features=128, bias=True)\n",
      "    (drop2): Dropout2d(p=0.5, inplace=False)\n",
      "    (fc16): Linear(in_features=128, out_features=10, bias=True)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "class Net(nn.Module):\n",
    "\n",
    "    def __init__(self):\n",
    "        super(Net,self).__init__()\n",
    "        self.conv1 = nn.Conv2d(3,64,3,padding=1)\n",
    "        self.conv2 = nn.Conv2d(64,64,3,padding=1)\n",
    "        self.pool1 = nn.MaxPool2d(2, 2)\n",
    "        self.bn1 = nn.BatchNorm2d(64)\n",
    "        self.relu1 = nn.ReLU()\n",
    "\n",
    "        self.conv3 = nn.Conv2d(64,128,3,padding=1)\n",
    "        self.conv4 = nn.Conv2d(128, 128, 3,padding=1)\n",
    "        self.pool2 = nn.MaxPool2d(2, 2, padding=1)\n",
    "        self.bn2 = nn.BatchNorm2d(128)\n",
    "        self.relu2 = nn.ReLU()\n",
    "\n",
    "        self.conv5 = nn.Conv2d(128,128, 3,padding=1)\n",
    "        self.conv6 = nn.Conv2d(128, 128, 3,padding=1)\n",
    "        self.conv7 = nn.Conv2d(128, 128, 1,padding=1)\n",
    "        self.pool3 = nn.MaxPool2d(2, 2, padding=1)\n",
    "        self.bn3 = nn.BatchNorm2d(128)\n",
    "        self.relu3 = nn.ReLU()\n",
    "\n",
    "        self.conv8 = nn.Conv2d(128, 256, 3,padding=1)\n",
    "        self.conv9 = nn.Conv2d(256, 256, 3, padding=1)\n",
    "        self.conv10 = nn.Conv2d(256, 256, 1, padding=1)\n",
    "        self.pool4 = nn.MaxPool2d(2, 2, padding=1)\n",
    "        self.bn4 = nn.BatchNorm2d(256)\n",
    "        self.relu4 = nn.ReLU()\n",
    "\n",
    "        self.conv11 = nn.Conv2d(256, 512, 3, padding=1)\n",
    "        self.conv12 = nn.Conv2d(512, 512, 3, padding=1)\n",
    "        self.conv13 = nn.Conv2d(512, 512, 1, padding=1)\n",
    "        self.pool5 = nn.MaxPool2d(2, 2, padding=1)\n",
    "        self.bn5 = nn.BatchNorm2d(512)\n",
    "        self.relu5 = nn.ReLU()\n",
    "\n",
    "        self.fc14 = nn.Linear(512*4*4,1024)\n",
    "        self.drop1 = nn.Dropout2d()\n",
    "        self.fc15 = nn.Linear(1024,128)\n",
    "        self.drop2 = nn.Dropout2d()\n",
    "        self.fc16 = nn.Linear(128,10)\n",
    "\n",
    "\n",
    "    def forward(self,x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.conv2(x)\n",
    "        x = self.pool1(x)\n",
    "        x = self.bn1(x)\n",
    "        x = self.relu1(x)\n",
    "\n",
    "\n",
    "        x = self.conv3(x)\n",
    "        x = self.conv4(x)\n",
    "        x = self.pool2(x)\n",
    "        x = self.bn2(x)\n",
    "        x = self.relu2(x)\n",
    "\n",
    "        x = self.conv5(x)\n",
    "        x = self.conv6(x)\n",
    "        x = self.conv7(x)\n",
    "        x = self.pool3(x)\n",
    "        x = self.bn3(x)\n",
    "        x = self.relu3(x)\n",
    "\n",
    "        x = self.conv8(x)\n",
    "        x = self.conv9(x)\n",
    "        x = self.conv10(x)\n",
    "        x = self.pool4(x)\n",
    "        x = self.bn4(x)\n",
    "        x = self.relu4(x)\n",
    "\n",
    "        x = self.conv11(x)\n",
    "        x = self.conv12(x)\n",
    "        x = self.conv13(x)\n",
    "        x = self.pool5(x)\n",
    "        x = self.bn5(x)\n",
    "        x = self.relu5(x)\n",
    "        # print(\" x shape \",x.size())\n",
    "        x = x.view(-1,512*4*4)\n",
    "        x = F.relu(self.fc14(x))\n",
    "        x = self.drop1(x)\n",
    "        x = F.relu(self.fc15(x))\n",
    "        x = self.drop2(x)\n",
    "        x = self.fc16(x)\n",
    "\n",
    "        return x\n",
    "\n",
    "model = Net().to(device)\n",
    "if device == 'cuda':\n",
    "    model = torch.nn.DataParallel(model)\n",
    "    cudnn.benchmark = True\n",
    "\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.01,\n",
    "                      momentum=0.9, weight_decay=5e-4)\n",
    "scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=200)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# total_batch = len(data_loader)\n",
    "# model.train()\n",
    "# for epoch in range(training_epochs):\n",
    "#     avg_cost = 0\n",
    "\n",
    "#     for X, Y in data_loader:\n",
    "#         X = torch.autograd.Variable(X).to(device)\n",
    "#         Y = Y.to(device)\n",
    "\n",
    "#         optimizer.zero_grad()\n",
    "#         hypothesis = model(X)\n",
    "#         cost = criterion(hypothesis, Y)\n",
    "#         cost.backward()\n",
    "#         optimizer.step()\n",
    "\n",
    "#         avg_cost += cost / total_batch\n",
    "\n",
    "#     print('Epoch:', '%04d' % (epoch + 1), 'cost =', '{:.9f}'.format(avg_cost))\n",
    "\n",
    "# print('Learning finished')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32 ['cifar_test05-17--14-37-12.pth', 'cifar_test05-17--14-54-02.pth', 'cifar_test05-17--15-14-35.pth', 'cifar_test05-17--16-26-58.pth', 'cifar_test05-21--16-54-11.pth', 'cifar_test05-21--17-14-44.pth', 'cifar_test05-21--17-32-48.pth', 'cifar_test05-21--17-54-18.pth', 'cifar_test05-21--19-39-49.pth', 'cifar_test05-21--20-32-02.pth', 'cifar_test06-05--18-46-57.pth', 'cifar_test06-05--19-22-49.pth', 'cifar_test06-05--19-58-22.pth', 'cifar_test06-05--20-48-07.pth', 'cifar_test06-05--21-21-48.pth', 'cifar_test06-05--21-51-18.pth', 'cifar_test06-07--18-36-08.pth', 'cifar_test06-07--19-12-04.pth', 'cifar_test06-21--17-02-50.pth', 'cifar_test06-21--19-17-17.pth', 'cifar_t_attack05-21--21-50-44.pth', 'cifar_t_attack05-22--17-27-17.pth', 'cifar_t_attack05-23--19-52-34.pth', 'cifar_t_attack05-23--20-12-15.pth', 'cifar_t_attack05-26--21-49-39.pth', 'cifar_t_attack05-26--22-24-59.pth', 'cifar_t_attack05-26--23-29-05.pth', 'cifar_t_attack05-27--00-00-20.pth', 'cifar_t_attack06-05--18-56-04.pth', 'cifar_t_attack06-05--19-27-03.pth', 'cifar_t_attack06-05--20-10-53.pth', 'cifar_t_attack06-05--20-50-31.pth']\n"
     ]
    }
   ],
   "source": [
    "# model.load_state_dict(torch.load(\"./myfed_normal_save/model18-32-05.pth\")[\"state_dict\"])\n",
    "dir = os.listdir(\"./saved_models\")\n",
    "modelnames = []\n",
    "for mt in dir:\n",
    "    if(mt[0:len(\"cifar_\")] == \"cifar_\"):\n",
    "        modelnames.append(mt)\n",
    "print(len(modelnames),modelnames)\n",
    "modelset = []\n",
    "for mn in modelnames:\n",
    "    modelset.append([model.load_state_dict(torch.load(\"./saved_models/\"+mn)[\"state_dict\"]),mn])\n",
    "savepath = \"./metric/vr_metric_single_convFeature_extract_layers=\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # model.load_state_dict(torch.load(\"./myfed_normal_save/model18-32-05.pth\")[\"state_dict\"])\n",
    "# dir = os.listdir(\"./merge_save\")\n",
    "# modelnames = []\n",
    "# for mt in dir:\n",
    "#     if(mt[0:len(\"merge_cifartest\")] == \"merge_cifartest\"):\n",
    "#         modelnames.append(mt)\n",
    "# print(modelnames)\n",
    "# modelset = []\n",
    "# for mn in modelnames:\n",
    "#     modelset.append([model.load_state_dict(torch.load(\"./merge_save/\"+mn)[\"state_dict\"]),mn])\n",
    "# # print(dir)\n",
    "# savepath = \"./metric/vr_metric_convFeature_extract_layers=\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./metric/vr_metric_single_convFeature_extract_layers=cifar_test05-17--14-37-12.pth0.dat\n",
      "./metric/vr_metric_single_convFeature_extract_layers=cifar_test05-17--14-37-12.pth1.dat\n",
      "./metric/vr_metric_single_convFeature_extract_layers=cifar_test05-17--14-37-12.pth2.dat\n",
      "./metric/vr_metric_single_convFeature_extract_layers=cifar_test05-17--14-37-12.pth3.dat\n",
      "./metric/vr_metric_single_convFeature_extract_layers=cifar_test05-17--14-54-02.pth0.dat\n",
      "./metric/vr_metric_single_convFeature_extract_layers=cifar_test05-17--14-54-02.pth1.dat\n",
      "./metric/vr_metric_single_convFeature_extract_layers=cifar_test05-17--14-54-02.pth2.dat\n",
      "./metric/vr_metric_single_convFeature_extract_layers=cifar_test05-17--14-54-02.pth3.dat\n",
      "./metric/vr_metric_single_convFeature_extract_layers=cifar_test05-17--15-14-35.pth0.dat\n",
      "./metric/vr_metric_single_convFeature_extract_layers=cifar_test05-17--15-14-35.pth1.dat\n",
      "./metric/vr_metric_single_convFeature_extract_layers=cifar_test05-17--15-14-35.pth2.dat\n",
      "./metric/vr_metric_single_convFeature_extract_layers=cifar_test05-17--15-14-35.pth3.dat\n",
      "./metric/vr_metric_single_convFeature_extract_layers=cifar_test05-17--16-26-58.pth0.dat\n",
      "./metric/vr_metric_single_convFeature_extract_layers=cifar_test05-17--16-26-58.pth1.dat\n",
      "./metric/vr_metric_single_convFeature_extract_layers=cifar_test05-17--16-26-58.pth2.dat\n",
      "./metric/vr_metric_single_convFeature_extract_layers=cifar_test05-17--16-26-58.pth3.dat\n",
      "./metric/vr_metric_single_convFeature_extract_layers=cifar_test05-21--16-54-11.pth0.dat\n",
      "./metric/vr_metric_single_convFeature_extract_layers=cifar_test05-21--16-54-11.pth1.dat\n",
      "./metric/vr_metric_single_convFeature_extract_layers=cifar_test05-21--16-54-11.pth2.dat\n",
      "./metric/vr_metric_single_convFeature_extract_layers=cifar_test05-21--16-54-11.pth3.dat\n",
      "./metric/vr_metric_single_convFeature_extract_layers=cifar_test05-21--17-14-44.pth0.dat\n",
      "./metric/vr_metric_single_convFeature_extract_layers=cifar_test05-21--17-14-44.pth1.dat\n",
      "./metric/vr_metric_single_convFeature_extract_layers=cifar_test05-21--17-14-44.pth2.dat\n",
      "./metric/vr_metric_single_convFeature_extract_layers=cifar_test05-21--17-14-44.pth3.dat\n",
      "./metric/vr_metric_single_convFeature_extract_layers=cifar_test05-21--17-32-48.pth0.dat\n",
      "./metric/vr_metric_single_convFeature_extract_layers=cifar_test05-21--17-32-48.pth1.dat\n",
      "./metric/vr_metric_single_convFeature_extract_layers=cifar_test05-21--17-32-48.pth2.dat\n",
      "./metric/vr_metric_single_convFeature_extract_layers=cifar_test05-21--17-32-48.pth3.dat\n",
      "./metric/vr_metric_single_convFeature_extract_layers=cifar_test05-21--17-54-18.pth0.dat\n",
      "./metric/vr_metric_single_convFeature_extract_layers=cifar_test05-21--17-54-18.pth1.dat\n",
      "./metric/vr_metric_single_convFeature_extract_layers=cifar_test05-21--17-54-18.pth2.dat\n",
      "./metric/vr_metric_single_convFeature_extract_layers=cifar_test05-21--17-54-18.pth3.dat\n",
      "./metric/vr_metric_single_convFeature_extract_layers=cifar_test05-21--19-39-49.pth0.dat\n",
      "./metric/vr_metric_single_convFeature_extract_layers=cifar_test05-21--19-39-49.pth1.dat\n",
      "./metric/vr_metric_single_convFeature_extract_layers=cifar_test05-21--19-39-49.pth2.dat\n",
      "./metric/vr_metric_single_convFeature_extract_layers=cifar_test05-21--19-39-49.pth3.dat\n",
      "./metric/vr_metric_single_convFeature_extract_layers=cifar_test05-21--20-32-02.pth0.dat\n",
      "./metric/vr_metric_single_convFeature_extract_layers=cifar_test05-21--20-32-02.pth1.dat\n",
      "./metric/vr_metric_single_convFeature_extract_layers=cifar_test05-21--20-32-02.pth2.dat\n",
      "./metric/vr_metric_single_convFeature_extract_layers=cifar_test05-21--20-32-02.pth3.dat\n",
      "./metric/vr_metric_single_convFeature_extract_layers=cifar_test06-05--18-46-57.pth0.dat\n",
      "./metric/vr_metric_single_convFeature_extract_layers=cifar_test06-05--18-46-57.pth1.dat\n",
      "./metric/vr_metric_single_convFeature_extract_layers=cifar_test06-05--18-46-57.pth2.dat\n",
      "./metric/vr_metric_single_convFeature_extract_layers=cifar_test06-05--18-46-57.pth3.dat\n",
      "./metric/vr_metric_single_convFeature_extract_layers=cifar_test06-05--19-22-49.pth0.dat\n",
      "./metric/vr_metric_single_convFeature_extract_layers=cifar_test06-05--19-22-49.pth1.dat\n",
      "./metric/vr_metric_single_convFeature_extract_layers=cifar_test06-05--19-22-49.pth2.dat\n",
      "./metric/vr_metric_single_convFeature_extract_layers=cifar_test06-05--19-22-49.pth3.dat\n",
      "./metric/vr_metric_single_convFeature_extract_layers=cifar_test06-05--19-58-22.pth0.dat\n",
      "./metric/vr_metric_single_convFeature_extract_layers=cifar_test06-05--19-58-22.pth1.dat\n",
      "./metric/vr_metric_single_convFeature_extract_layers=cifar_test06-05--19-58-22.pth2.dat\n",
      "./metric/vr_metric_single_convFeature_extract_layers=cifar_test06-05--19-58-22.pth3.dat\n",
      "./metric/vr_metric_single_convFeature_extract_layers=cifar_test06-05--20-48-07.pth0.dat\n",
      "./metric/vr_metric_single_convFeature_extract_layers=cifar_test06-05--20-48-07.pth1.dat\n",
      "./metric/vr_metric_single_convFeature_extract_layers=cifar_test06-05--20-48-07.pth2.dat\n",
      "./metric/vr_metric_single_convFeature_extract_layers=cifar_test06-05--20-48-07.pth3.dat\n",
      "./metric/vr_metric_single_convFeature_extract_layers=cifar_test06-05--21-21-48.pth0.dat\n",
      "./metric/vr_metric_single_convFeature_extract_layers=cifar_test06-05--21-21-48.pth1.dat\n",
      "./metric/vr_metric_single_convFeature_extract_layers=cifar_test06-05--21-21-48.pth2.dat\n",
      "./metric/vr_metric_single_convFeature_extract_layers=cifar_test06-05--21-21-48.pth3.dat\n",
      "./metric/vr_metric_single_convFeature_extract_layers=cifar_test06-05--21-51-18.pth0.dat\n",
      "./metric/vr_metric_single_convFeature_extract_layers=cifar_test06-05--21-51-18.pth1.dat\n",
      "./metric/vr_metric_single_convFeature_extract_layers=cifar_test06-05--21-51-18.pth2.dat\n",
      "./metric/vr_metric_single_convFeature_extract_layers=cifar_test06-05--21-51-18.pth3.dat\n",
      "./metric/vr_metric_single_convFeature_extract_layers=cifar_test06-07--18-36-08.pth0.dat\n",
      "./metric/vr_metric_single_convFeature_extract_layers=cifar_test06-07--18-36-08.pth1.dat\n",
      "./metric/vr_metric_single_convFeature_extract_layers=cifar_test06-07--18-36-08.pth2.dat\n",
      "./metric/vr_metric_single_convFeature_extract_layers=cifar_test06-07--18-36-08.pth3.dat\n",
      "./metric/vr_metric_single_convFeature_extract_layers=cifar_test06-07--19-12-04.pth0.dat\n",
      "./metric/vr_metric_single_convFeature_extract_layers=cifar_test06-07--19-12-04.pth1.dat\n",
      "./metric/vr_metric_single_convFeature_extract_layers=cifar_test06-07--19-12-04.pth2.dat\n",
      "./metric/vr_metric_single_convFeature_extract_layers=cifar_test06-07--19-12-04.pth3.dat\n",
      "./metric/vr_metric_single_convFeature_extract_layers=cifar_test06-21--17-02-50.pth0.dat\n",
      "./metric/vr_metric_single_convFeature_extract_layers=cifar_test06-21--17-02-50.pth1.dat\n",
      "./metric/vr_metric_single_convFeature_extract_layers=cifar_test06-21--17-02-50.pth2.dat\n",
      "./metric/vr_metric_single_convFeature_extract_layers=cifar_test06-21--17-02-50.pth3.dat\n",
      "./metric/vr_metric_single_convFeature_extract_layers=cifar_test06-21--19-17-17.pth0.dat\n",
      "./metric/vr_metric_single_convFeature_extract_layers=cifar_test06-21--19-17-17.pth1.dat\n",
      "./metric/vr_metric_single_convFeature_extract_layers=cifar_test06-21--19-17-17.pth2.dat\n",
      "./metric/vr_metric_single_convFeature_extract_layers=cifar_test06-21--19-17-17.pth3.dat\n",
      "./metric/vr_metric_single_convFeature_extract_layers=cifar_t_attack05-21--21-50-44.pth0.dat\n",
      "./metric/vr_metric_single_convFeature_extract_layers=cifar_t_attack05-21--21-50-44.pth1.dat\n",
      "./metric/vr_metric_single_convFeature_extract_layers=cifar_t_attack05-21--21-50-44.pth2.dat\n",
      "./metric/vr_metric_single_convFeature_extract_layers=cifar_t_attack05-21--21-50-44.pth3.dat\n",
      "./metric/vr_metric_single_convFeature_extract_layers=cifar_t_attack05-22--17-27-17.pth0.dat\n",
      "./metric/vr_metric_single_convFeature_extract_layers=cifar_t_attack05-22--17-27-17.pth1.dat\n",
      "./metric/vr_metric_single_convFeature_extract_layers=cifar_t_attack05-22--17-27-17.pth2.dat\n",
      "./metric/vr_metric_single_convFeature_extract_layers=cifar_t_attack05-22--17-27-17.pth3.dat\n",
      "./metric/vr_metric_single_convFeature_extract_layers=cifar_t_attack05-23--19-52-34.pth0.dat\n",
      "./metric/vr_metric_single_convFeature_extract_layers=cifar_t_attack05-23--19-52-34.pth1.dat\n",
      "./metric/vr_metric_single_convFeature_extract_layers=cifar_t_attack05-23--19-52-34.pth2.dat\n",
      "./metric/vr_metric_single_convFeature_extract_layers=cifar_t_attack05-23--19-52-34.pth3.dat\n",
      "./metric/vr_metric_single_convFeature_extract_layers=cifar_t_attack05-23--20-12-15.pth0.dat\n",
      "./metric/vr_metric_single_convFeature_extract_layers=cifar_t_attack05-23--20-12-15.pth1.dat\n",
      "./metric/vr_metric_single_convFeature_extract_layers=cifar_t_attack05-23--20-12-15.pth2.dat\n",
      "./metric/vr_metric_single_convFeature_extract_layers=cifar_t_attack05-23--20-12-15.pth3.dat\n",
      "./metric/vr_metric_single_convFeature_extract_layers=cifar_t_attack05-26--21-49-39.pth0.dat\n",
      "./metric/vr_metric_single_convFeature_extract_layers=cifar_t_attack05-26--21-49-39.pth1.dat\n",
      "./metric/vr_metric_single_convFeature_extract_layers=cifar_t_attack05-26--21-49-39.pth2.dat\n",
      "./metric/vr_metric_single_convFeature_extract_layers=cifar_t_attack05-26--21-49-39.pth3.dat\n",
      "./metric/vr_metric_single_convFeature_extract_layers=cifar_t_attack05-26--22-24-59.pth0.dat\n",
      "./metric/vr_metric_single_convFeature_extract_layers=cifar_t_attack05-26--22-24-59.pth1.dat\n",
      "./metric/vr_metric_single_convFeature_extract_layers=cifar_t_attack05-26--22-24-59.pth2.dat\n",
      "./metric/vr_metric_single_convFeature_extract_layers=cifar_t_attack05-26--22-24-59.pth3.dat\n",
      "./metric/vr_metric_single_convFeature_extract_layers=cifar_t_attack05-26--23-29-05.pth0.dat\n",
      "./metric/vr_metric_single_convFeature_extract_layers=cifar_t_attack05-26--23-29-05.pth1.dat\n",
      "./metric/vr_metric_single_convFeature_extract_layers=cifar_t_attack05-26--23-29-05.pth2.dat\n",
      "./metric/vr_metric_single_convFeature_extract_layers=cifar_t_attack05-26--23-29-05.pth3.dat\n",
      "./metric/vr_metric_single_convFeature_extract_layers=cifar_t_attack05-27--00-00-20.pth0.dat\n",
      "./metric/vr_metric_single_convFeature_extract_layers=cifar_t_attack05-27--00-00-20.pth1.dat\n",
      "./metric/vr_metric_single_convFeature_extract_layers=cifar_t_attack05-27--00-00-20.pth2.dat\n",
      "./metric/vr_metric_single_convFeature_extract_layers=cifar_t_attack05-27--00-00-20.pth3.dat\n",
      "./metric/vr_metric_single_convFeature_extract_layers=cifar_t_attack06-05--18-56-04.pth0.dat\n",
      "./metric/vr_metric_single_convFeature_extract_layers=cifar_t_attack06-05--18-56-04.pth1.dat\n",
      "./metric/vr_metric_single_convFeature_extract_layers=cifar_t_attack06-05--18-56-04.pth2.dat\n",
      "./metric/vr_metric_single_convFeature_extract_layers=cifar_t_attack06-05--18-56-04.pth3.dat\n",
      "./metric/vr_metric_single_convFeature_extract_layers=cifar_t_attack06-05--19-27-03.pth0.dat\n",
      "./metric/vr_metric_single_convFeature_extract_layers=cifar_t_attack06-05--19-27-03.pth1.dat\n",
      "./metric/vr_metric_single_convFeature_extract_layers=cifar_t_attack06-05--19-27-03.pth2.dat\n",
      "./metric/vr_metric_single_convFeature_extract_layers=cifar_t_attack06-05--19-27-03.pth3.dat\n",
      "./metric/vr_metric_single_convFeature_extract_layers=cifar_t_attack06-05--20-10-53.pth0.dat\n",
      "./metric/vr_metric_single_convFeature_extract_layers=cifar_t_attack06-05--20-10-53.pth1.dat\n",
      "./metric/vr_metric_single_convFeature_extract_layers=cifar_t_attack06-05--20-10-53.pth2.dat\n",
      "./metric/vr_metric_single_convFeature_extract_layers=cifar_t_attack06-05--20-10-53.pth3.dat\n",
      "./metric/vr_metric_single_convFeature_extract_layers=cifar_t_attack06-05--20-50-31.pth0.dat\n",
      "./metric/vr_metric_single_convFeature_extract_layers=cifar_t_attack06-05--20-50-31.pth1.dat\n",
      "./metric/vr_metric_single_convFeature_extract_layers=cifar_t_attack06-05--20-50-31.pth2.dat\n",
      "./metric/vr_metric_single_convFeature_extract_layers=cifar_t_attack06-05--20-50-31.pth3.dat\n"
     ]
    }
   ],
   "source": [
    "for mode, modelname in modelset:\n",
    "    parm = {}\n",
    "    for name,parameters in model.named_parameters():\n",
    "        parm[name]=parameters\n",
    "        # print(parm[name]) \n",
    "    tensors = []\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "\n",
    "        t=10\n",
    "        group1 = []\n",
    "        group2 = []\n",
    "        group3 = []\n",
    "        group4 = []\n",
    "        for i in range(0,t):\n",
    "            \n",
    "            r = random.randint(0, (batch_size) - 1)\n",
    "\n",
    "            for X_test, Y_test in testloader:\n",
    "                X_test = X_test.to(device)\n",
    "                Y_test = Y_test.to(device)\n",
    "            \n",
    "\n",
    "            X_single_data = X_test[r]\n",
    "            Y_single_data = Y_test[r]\n",
    "\n",
    "            # print(X_single_data)\n",
    "            \n",
    "            layerP = model.module.conv1(torch.unsqueeze(X_single_data,dim=0))\n",
    "            # print(\"1\",layerP)\n",
    "            layerP = model.module.conv2(layerP)\n",
    "            # print(\"2\",layerP)\n",
    "            layerP = model.module.pool1(layerP)\n",
    "            layerP = model.module.bn1(layerP)\n",
    "            layerP = model.module.relu1(layerP)\n",
    "            # print(\"3\",layerP)\n",
    "            layerP = model.module.conv3(layerP)\n",
    "            layerP = model.module.conv4(layerP)\n",
    "            layerP = model.module.pool2(layerP)\n",
    "            layerP = model.module.bn2(layerP)\n",
    "            layerP = model.module.relu2(layerP)\n",
    "            \n",
    "            layerP = model.module.conv5(layerP)\n",
    "            layerP = model.module.conv6(layerP)\n",
    "            layerP = model.module.conv7(layerP)\n",
    "            layerP = model.module.pool3(layerP)\n",
    "            layerP = model.module.bn3(layerP)\n",
    "            layerP = model.module.relu3(layerP)\n",
    "            layerExtract0 = layerP.squeeze().reshape(-1,72)\n",
    "            # print(layerExtract0.shape)\n",
    "            # print(layerExtract0.cpu().detach().numpy()[0])\n",
    "            group1.append(layerExtract0.cpu().detach().numpy()[0])\n",
    "\n",
    "            layerP = model.module.conv8(layerP)\n",
    "            layerP = model.module.conv9(layerP)\n",
    "            layerP = model.module.conv10(layerP)\n",
    "            layerP = model.module.pool4(layerP)\n",
    "            layerP = model.module.bn4(layerP)\n",
    "            layerP = model.module.relu4(layerP)\n",
    "            # print(layerP.shape)\n",
    "            layerExtract1 = layerP.squeeze().reshape(-1,80)\n",
    "            group2.append(layerExtract1.cpu().detach().numpy()[0])\n",
    "\n",
    "            layerP = model.module.conv11(layerP)\n",
    "            layerP = model.module.conv12(layerP)\n",
    "            layerP = model.module.conv13(layerP)\n",
    "            layerP = model.module.pool5(layerP)\n",
    "            layerP = model.module.bn5(layerP)\n",
    "            layerP = model.module.relu5(layerP)\n",
    "            \n",
    "            layerExtract2 = layerP.squeeze().reshape(-1,128)\n",
    "            # print(layerExtract2.shape)\n",
    "            group3.append(layerExtract2.cpu().detach().numpy()[0])\n",
    "            layerP = layerP.detach().squeeze().reshape(-1,512*4*4)\n",
    "\n",
    "            tensor1 = torch.mm(layerP, parm['module.fc14.weight'].data.permute(1,0)) + parm['module.fc14.bias']\n",
    "            tensor1 = torch.mm(tensor1, parm['module.fc15.weight'].data.permute(1,0)) + parm['module.fc15.bias']\n",
    "            \n",
    "            group4.append(tensor1.cpu().detach().numpy()[0])\n",
    "\n",
    "    l = 0\n",
    "    for tensors in [group1, group2, group3, group4]:\n",
    "        # print(len(tensors))\n",
    "        nb = np.linspace(0,0,tensors[0].shape[0])\n",
    "        for i in tensors:\n",
    "            nb += i\n",
    "        nb /= t\n",
    "\n",
    "        ns = np.linspace(0,0,tensors[0].shape[0])\n",
    "        vp = np.linspace(0,0,tensors[0].shape[0] ** 2).reshape(tensors[0].shape[0],tensors[0].shape[0])\n",
    "\n",
    "        for i in range(0,len(ns)):\n",
    "            for nps in tensors:\n",
    "                ns[i] += nps[i] ** 2\n",
    "            ns[i] = ns[i] ** 0.5\n",
    "\n",
    "        for i in range(0,len(ns)):\n",
    "            for j in range(i+1,len(ns)):\n",
    "                for nps in tensors:\n",
    "                    vp[i,j] += (nps[i] - nb[i]) * (nps[j] - nb[j])\n",
    "                # vp[i,j] /= (ns[i] * ns[j])\n",
    "                vp[i,j] = vp[i,j] / (ns[i] * ns[j]) if ns[i] * ns[j] != 0 else vp[i,j]\n",
    "\n",
    "        dt = datetime.datetime.now()\n",
    "        # np.savetxt(\"./misc/vr_metric\"+dt.strftime(\"%d--%H-%M-%S\")+\".dat\", vp+vp.T, fmt=\"%1.5f\")\n",
    "        np.savetxt(savepath+modelname+str(l)+\".dat\", vp+vp.T, fmt=\"%1.5f\")\n",
    "        print(savepath+modelname+str(l)+\".dat\")\n",
    "        l += 1"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "61d7d72412218704c5ba1799d65c7a83b08e24a9ca7847de9a479f6f426633e7"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
