{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "# input_data shape\n",
    "Input: (batch_size, in_channel, width, height)\n",
    "# conv layer\n",
    "class torch.nn.Conv2d(in_channels, out_channels, kernel_size, stride=1, padding=0, dilation=1, groups=1, bias=True)\n",
    "input: (Batch_size, C_in, H_in, W_in)\n",
    "output: (Batch_size, C_out, H_out, W_out)\n",
    "\n",
    "weight(tensor): (out_channels, in_channels,kernel_size)\n",
    "bias(tensor): (out_channel)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "from itertools import product\n",
    "\n",
    "import time\n",
    "import numpy as np\n",
    "from sklearn import datasets\n",
    "from scipy.stats import multivariate_normal as mvn\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from ripser import Rips\n",
    "from persim import PersistenceImager\n",
    "\n",
    "import os\n",
    "import math\n",
    "\n",
    "import seaborn\n",
    "import pandas as pd\n",
    "import torch\n",
    "import random\n",
    "from torch import nn\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import persim\n",
    "\n",
    "import re\n",
    "import cv2\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "# for reproducibility\n",
    "random.seed(111)\n",
    "torch.manual_seed(777)\n",
    "if device == 'cuda':\n",
    "    torch.cuda.manual_seed_all(777)\n",
    "# parameters\n",
    "learning_rate = 0.001\n",
    "training_epochs = 120\n",
    "batchsize = 25\n",
    "testbatchsize = 10\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "# dir = os.listdir(\"./metric\")\n",
    "# data = []\n",
    "# a = []\n",
    "# for metric in dir:\n",
    "#     a = re.findall(\"\\d+\\.?\\d*\", metric)\n",
    "#     data.append([np.loadtxt(\"./metric/\"+metric), metric])\n",
    "#     # print(a[-2])\n",
    "#     print(metric[-2])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "class My_dataset(Dataset):\n",
    "    def __init__(self, train, index):\n",
    "        super().__init__()\n",
    "        if train:\n",
    "            dir_data = os.listdir(\"./grids_fed_vgg\")\n",
    "            path = \"./grids_fed_vgg/\"\n",
    "        else:\n",
    "            dir_data = os.listdir(\"./grids_fed_vgg_eval\")\n",
    "            path = \"./grids_fed_vgg_eval/\"\n",
    "        data = []\n",
    "        sample = []\n",
    "        distance = 1\n",
    "        T_normal = []\n",
    "        T_attack = []\n",
    "        normal_attack = [0,0]\n",
    "        for metric in dir_data[0:5]:\n",
    "            dgm = []\n",
    "            grid = pd.DataFrame(np.loadtxt(path+metric))\n",
    "            for i in range(grid.shape[0]):\n",
    "                for j in range(grid.shape[1]):\n",
    "                    if grid[i][j] > 0:\n",
    "                        dgm.append([i,j])\n",
    "            T_normal.append(dgm)\n",
    "        for metric in dir_data[-5:]:\n",
    "            dgm = []\n",
    "            grid = pd.DataFrame(np.loadtxt(path+metric))\n",
    "            for i in range(grid.shape[0]):\n",
    "                for j in range(grid.shape[1]):\n",
    "                    if grid[i][j] > 0:\n",
    "                        dgm.append([i,j])\n",
    "            T_attack.append(dgm)\n",
    "            \n",
    "        for metric in dir_data:\n",
    "            if int(re.findall(\"\\d+\\.?\\d*\", metric)[0]) in index:\n",
    "                sample.append([np.loadtxt(path+metric), metric])\n",
    "                label = int(\"attack\" in metric)\n",
    "\n",
    "                # if (label == 0):\n",
    "                #     distance_bottleneck, matching = persim.bottleneck(sample[len(sample)-1][0], T_normal[len(sample)-1], matching=True)\n",
    "                # else:\n",
    "                #     distance_bottleneck, matching = persim.bottleneck(sample[len(sample)-1][0], T_attack[len(sample)-1], matching=True)\n",
    "                # distance += distance_bottleneck\n",
    "                if len(sample) == 5:\n",
    "                    res = cv2.merge([i[0] for i in sample])\n",
    "                    res = np.transpose(res,(2,0,1))\n",
    "                    # d = 1/(1+math.exp(math.log(distance)))\n",
    "                    data.append([res, np.array((label,distance))])\n",
    "                    sample = []\n",
    "                    \n",
    "        for i in data:\n",
    "            normal_attack[int(i[1][0])] += 1\n",
    "        print(normal_attack)\n",
    "        normal_attack = [max(normal_attack), min(normal_attack)]\n",
    "        data.sort(key=lambda x: x[1][0])\n",
    "        data = data[0:normal_attack[1]]+data[-normal_attack[1]:]\n",
    "        normal_attack = [0,0]\n",
    "        for i in data:\n",
    "            normal_attack[int(i[1][0])] += 1\n",
    "        print(normal_attack)\n",
    "        \n",
    "        self.x = [item[0] for item in data]\n",
    "        self.y = [item[1] for item in data]\n",
    "        # self.y = [int(re.findall(\"\\d+\\.?\\d*\", item[1])[0]) for item in data]\n",
    "        self.src,  self.trg = [], []\n",
    "        \n",
    "\n",
    "        for i in range(len(data)):\n",
    "            self.src.append(self.x[i])\n",
    "            self.trg.append(self.y[i])\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        return self.src[index], self.trg[index]\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.src)\n",
    "\n",
    " # 或者return len(self.trg), src和trg长度一样\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[450, 190]\n",
      "[190, 190]\n",
      "[76, 95]\n",
      "[76, 76]\n",
      "train\n",
      "0\n",
      "torch.Size([25, 5, 128, 128])\n",
      "tensor([[1, 1],\n",
      "        [0, 1],\n",
      "        [1, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [1, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [1, 1],\n",
      "        [1, 1],\n",
      "        [1, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [1, 1],\n",
      "        [0, 1],\n",
      "        [1, 1],\n",
      "        [0, 1],\n",
      "        [1, 1],\n",
      "        [0, 1],\n",
      "        [1, 1],\n",
      "        [1, 1]], dtype=torch.int32)\n",
      "1\n",
      "torch.Size([25, 5, 128, 128])\n",
      "tensor([[1, 1],\n",
      "        [1, 1],\n",
      "        [1, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [1, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [1, 1],\n",
      "        [0, 1],\n",
      "        [1, 1],\n",
      "        [1, 1],\n",
      "        [0, 1],\n",
      "        [1, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [1, 1],\n",
      "        [0, 1],\n",
      "        [1, 1],\n",
      "        [1, 1],\n",
      "        [1, 1],\n",
      "        [1, 1]], dtype=torch.int32)\n",
      "2\n",
      "torch.Size([25, 5, 128, 128])\n",
      "tensor([[1, 1],\n",
      "        [0, 1],\n",
      "        [1, 1],\n",
      "        [0, 1],\n",
      "        [1, 1],\n",
      "        [1, 1],\n",
      "        [0, 1],\n",
      "        [1, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [1, 1],\n",
      "        [0, 1],\n",
      "        [1, 1],\n",
      "        [1, 1],\n",
      "        [0, 1],\n",
      "        [1, 1],\n",
      "        [0, 1],\n",
      "        [1, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [1, 1],\n",
      "        [0, 1]], dtype=torch.int32)\n",
      "3\n",
      "torch.Size([25, 5, 128, 128])\n",
      "tensor([[0, 1],\n",
      "        [1, 1],\n",
      "        [1, 1],\n",
      "        [1, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [1, 1],\n",
      "        [1, 1],\n",
      "        [1, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [1, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [1, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [1, 1],\n",
      "        [1, 1],\n",
      "        [0, 1],\n",
      "        [1, 1]], dtype=torch.int32)\n",
      "4\n",
      "torch.Size([25, 5, 128, 128])\n",
      "tensor([[1, 1],\n",
      "        [0, 1],\n",
      "        [1, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [1, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [1, 1],\n",
      "        [0, 1],\n",
      "        [1, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [1, 1],\n",
      "        [1, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [1, 1],\n",
      "        [0, 1],\n",
      "        [1, 1],\n",
      "        [1, 1],\n",
      "        [1, 1]], dtype=torch.int32)\n",
      "5\n",
      "torch.Size([25, 5, 128, 128])\n",
      "tensor([[1, 1],\n",
      "        [0, 1],\n",
      "        [1, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [1, 1],\n",
      "        [1, 1],\n",
      "        [1, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [1, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [1, 1],\n",
      "        [0, 1],\n",
      "        [1, 1],\n",
      "        [0, 1],\n",
      "        [1, 1],\n",
      "        [1, 1],\n",
      "        [0, 1],\n",
      "        [1, 1],\n",
      "        [0, 1]], dtype=torch.int32)\n",
      "6\n",
      "torch.Size([25, 5, 128, 128])\n",
      "tensor([[1, 1],\n",
      "        [0, 1],\n",
      "        [1, 1],\n",
      "        [1, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [1, 1],\n",
      "        [0, 1],\n",
      "        [1, 1],\n",
      "        [0, 1],\n",
      "        [1, 1],\n",
      "        [1, 1],\n",
      "        [0, 1],\n",
      "        [1, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [1, 1],\n",
      "        [1, 1],\n",
      "        [0, 1],\n",
      "        [1, 1],\n",
      "        [1, 1],\n",
      "        [1, 1],\n",
      "        [1, 1],\n",
      "        [0, 1],\n",
      "        [1, 1]], dtype=torch.int32)\n",
      "7\n",
      "torch.Size([25, 5, 128, 128])\n",
      "tensor([[1, 1],\n",
      "        [1, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [1, 1],\n",
      "        [0, 1],\n",
      "        [1, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [1, 1],\n",
      "        [1, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [1, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [1, 1],\n",
      "        [1, 1],\n",
      "        [1, 1]], dtype=torch.int32)\n",
      "8\n",
      "torch.Size([25, 5, 128, 128])\n",
      "tensor([[1, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [1, 1],\n",
      "        [1, 1],\n",
      "        [1, 1],\n",
      "        [0, 1],\n",
      "        [1, 1],\n",
      "        [1, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [1, 1],\n",
      "        [1, 1],\n",
      "        [0, 1],\n",
      "        [1, 1],\n",
      "        [1, 1],\n",
      "        [1, 1],\n",
      "        [1, 1]], dtype=torch.int32)\n",
      "9\n",
      "torch.Size([25, 5, 128, 128])\n",
      "tensor([[1, 1],\n",
      "        [0, 1],\n",
      "        [1, 1],\n",
      "        [0, 1],\n",
      "        [1, 1],\n",
      "        [1, 1],\n",
      "        [1, 1],\n",
      "        [1, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [1, 1],\n",
      "        [1, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [1, 1],\n",
      "        [0, 1],\n",
      "        [1, 1],\n",
      "        [1, 1],\n",
      "        [0, 1],\n",
      "        [1, 1],\n",
      "        [0, 1],\n",
      "        [1, 1],\n",
      "        [0, 1],\n",
      "        [0, 1]], dtype=torch.int32)\n",
      "10\n",
      "torch.Size([25, 5, 128, 128])\n",
      "tensor([[0, 1],\n",
      "        [1, 1],\n",
      "        [0, 1],\n",
      "        [1, 1],\n",
      "        [1, 1],\n",
      "        [1, 1],\n",
      "        [0, 1],\n",
      "        [1, 1],\n",
      "        [0, 1],\n",
      "        [1, 1],\n",
      "        [1, 1],\n",
      "        [0, 1],\n",
      "        [1, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [1, 1],\n",
      "        [1, 1],\n",
      "        [1, 1],\n",
      "        [1, 1],\n",
      "        [0, 1]], dtype=torch.int32)\n",
      "11\n",
      "torch.Size([25, 5, 128, 128])\n",
      "tensor([[1, 1],\n",
      "        [1, 1],\n",
      "        [1, 1],\n",
      "        [1, 1],\n",
      "        [0, 1],\n",
      "        [1, 1],\n",
      "        [0, 1],\n",
      "        [1, 1],\n",
      "        [1, 1],\n",
      "        [1, 1],\n",
      "        [0, 1],\n",
      "        [1, 1],\n",
      "        [0, 1],\n",
      "        [1, 1],\n",
      "        [0, 1],\n",
      "        [1, 1],\n",
      "        [1, 1],\n",
      "        [1, 1],\n",
      "        [1, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [1, 1],\n",
      "        [1, 1],\n",
      "        [1, 1],\n",
      "        [1, 1]], dtype=torch.int32)\n",
      "12\n",
      "torch.Size([25, 5, 128, 128])\n",
      "tensor([[1, 1],\n",
      "        [1, 1],\n",
      "        [0, 1],\n",
      "        [1, 1],\n",
      "        [0, 1],\n",
      "        [1, 1],\n",
      "        [1, 1],\n",
      "        [1, 1],\n",
      "        [1, 1],\n",
      "        [0, 1],\n",
      "        [1, 1],\n",
      "        [0, 1],\n",
      "        [1, 1],\n",
      "        [1, 1],\n",
      "        [1, 1],\n",
      "        [0, 1],\n",
      "        [1, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [1, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [1, 1],\n",
      "        [1, 1]], dtype=torch.int32)\n",
      "13\n",
      "torch.Size([25, 5, 128, 128])\n",
      "tensor([[1, 1],\n",
      "        [0, 1],\n",
      "        [1, 1],\n",
      "        [0, 1],\n",
      "        [1, 1],\n",
      "        [1, 1],\n",
      "        [1, 1],\n",
      "        [1, 1],\n",
      "        [0, 1],\n",
      "        [1, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [1, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [1, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [1, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [1, 1]], dtype=torch.int32)\n",
      "14\n",
      "torch.Size([25, 5, 128, 128])\n",
      "tensor([[1, 1],\n",
      "        [1, 1],\n",
      "        [0, 1],\n",
      "        [1, 1],\n",
      "        [0, 1],\n",
      "        [1, 1],\n",
      "        [1, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [1, 1],\n",
      "        [1, 1],\n",
      "        [1, 1],\n",
      "        [1, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [1, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [1, 1],\n",
      "        [0, 1],\n",
      "        [1, 1]], dtype=torch.int32)\n",
      "15\n",
      "torch.Size([5, 5, 128, 128])\n",
      "tensor([[0, 1],\n",
      "        [1, 1],\n",
      "        [1, 1],\n",
      "        [1, 1],\n",
      "        [1, 1]], dtype=torch.int32)\n",
      "test\n",
      "0\n",
      "torch.Size([10, 5, 128, 128])\n",
      "tensor([[0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1]], dtype=torch.int32)\n",
      "1\n",
      "torch.Size([10, 5, 128, 128])\n",
      "tensor([[0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1]], dtype=torch.int32)\n",
      "2\n",
      "torch.Size([10, 5, 128, 128])\n",
      "tensor([[0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1]], dtype=torch.int32)\n",
      "3\n",
      "torch.Size([10, 5, 128, 128])\n",
      "tensor([[0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1]], dtype=torch.int32)\n",
      "4\n",
      "torch.Size([10, 5, 128, 128])\n",
      "tensor([[0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1]], dtype=torch.int32)\n",
      "5\n",
      "torch.Size([10, 5, 128, 128])\n",
      "tensor([[0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1]], dtype=torch.int32)\n",
      "6\n",
      "torch.Size([10, 5, 128, 128])\n",
      "tensor([[0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1]], dtype=torch.int32)\n",
      "7\n",
      "torch.Size([10, 5, 128, 128])\n",
      "tensor([[0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [1, 1],\n",
      "        [1, 1],\n",
      "        [1, 1],\n",
      "        [1, 1]], dtype=torch.int32)\n",
      "8\n",
      "torch.Size([10, 5, 128, 128])\n",
      "tensor([[1, 1],\n",
      "        [1, 1],\n",
      "        [1, 1],\n",
      "        [1, 1],\n",
      "        [1, 1],\n",
      "        [1, 1],\n",
      "        [1, 1],\n",
      "        [1, 1],\n",
      "        [1, 1],\n",
      "        [1, 1]], dtype=torch.int32)\n",
      "9\n",
      "torch.Size([10, 5, 128, 128])\n",
      "tensor([[1, 1],\n",
      "        [1, 1],\n",
      "        [1, 1],\n",
      "        [1, 1],\n",
      "        [1, 1],\n",
      "        [1, 1],\n",
      "        [1, 1],\n",
      "        [1, 1],\n",
      "        [1, 1],\n",
      "        [1, 1]], dtype=torch.int32)\n",
      "10\n",
      "torch.Size([10, 5, 128, 128])\n",
      "tensor([[1, 1],\n",
      "        [1, 1],\n",
      "        [1, 1],\n",
      "        [1, 1],\n",
      "        [1, 1],\n",
      "        [1, 1],\n",
      "        [1, 1],\n",
      "        [1, 1],\n",
      "        [1, 1],\n",
      "        [1, 1]], dtype=torch.int32)\n",
      "11\n",
      "torch.Size([10, 5, 128, 128])\n",
      "tensor([[1, 1],\n",
      "        [1, 1],\n",
      "        [1, 1],\n",
      "        [1, 1],\n",
      "        [1, 1],\n",
      "        [1, 1],\n",
      "        [1, 1],\n",
      "        [1, 1],\n",
      "        [1, 1],\n",
      "        [1, 1]], dtype=torch.int32)\n",
      "12\n",
      "torch.Size([10, 5, 128, 128])\n",
      "tensor([[1, 1],\n",
      "        [1, 1],\n",
      "        [1, 1],\n",
      "        [1, 1],\n",
      "        [1, 1],\n",
      "        [1, 1],\n",
      "        [1, 1],\n",
      "        [1, 1],\n",
      "        [1, 1],\n",
      "        [1, 1]], dtype=torch.int32)\n",
      "13\n",
      "torch.Size([10, 5, 128, 128])\n",
      "tensor([[1, 1],\n",
      "        [1, 1],\n",
      "        [1, 1],\n",
      "        [1, 1],\n",
      "        [1, 1],\n",
      "        [1, 1],\n",
      "        [1, 1],\n",
      "        [1, 1],\n",
      "        [1, 1],\n",
      "        [1, 1]], dtype=torch.int32)\n",
      "14\n",
      "torch.Size([10, 5, 128, 128])\n",
      "tensor([[1, 1],\n",
      "        [1, 1],\n",
      "        [1, 1],\n",
      "        [1, 1],\n",
      "        [1, 1],\n",
      "        [1, 1],\n",
      "        [1, 1],\n",
      "        [1, 1],\n",
      "        [1, 1],\n",
      "        [1, 1]], dtype=torch.int32)\n",
      "15\n",
      "torch.Size([2, 5, 128, 128])\n",
      "tensor([[1, 1],\n",
      "        [1, 1]], dtype=torch.int32)\n"
     ]
    }
   ],
   "source": [
    "data_tf = transforms.Compose(\n",
    "    [transforms.ToTensor(),\n",
    "     transforms.Normalize([0.5], [0.5])])\n",
    "     \n",
    "data_train = My_dataset(train=True, index=[i for i in range(70,80)])\n",
    "data_test = My_dataset(train=False, index=[i for i in range(70,80)])\n",
    "data_loader_train = DataLoader(data_train, batch_size=batchsize, shuffle=True)\n",
    "data_loader_test = DataLoader(data_test, batch_size=testbatchsize, shuffle=False)\n",
    "\n",
    "\n",
    "# i_batch的多少根据batch size和def __len__(self)返回的长度确定\n",
    "# batch_data返回的值根据def __getitem__(self, index)来确定\n",
    "# 对训练集：(不太清楚enumerate返回什么的时候就多print试试)\n",
    "print(\"train\")\n",
    "for i_batch, batch_data in enumerate(data_loader_train):\n",
    "    print(i_batch)  # 打印batch编号\n",
    "    print(batch_data[0].shape)  # 打印该batch里面src\n",
    "    print(batch_data[1])  # 打印该batch里面trg\n",
    "# # 对测试集：（下面的语句也可以）\n",
    "print(\"test\")\n",
    "for i_batch, batch_data in enumerate(data_loader_test):\n",
    "    print(i_batch)  # 打印batch编号\n",
    "    print(batch_data[0].shape)  # 打印该batch里面src\n",
    "    print(batch_data[1])  # 打印该batch里面trg\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "class MyNet(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(MyNet, self).__init__()\n",
    "        self.layer1 = torch.nn.Sequential(\n",
    "            torch.nn.Conv2d(5, 16, kernel_size=64),\n",
    "            torch.nn.BatchNorm2d(16),\n",
    "            torch.nn.ReLU(inplace=True)\n",
    "        )\n",
    "\n",
    "        self.layer2 = torch.nn.Sequential(\n",
    "            torch.nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        )\n",
    "\n",
    "        self.fc = torch.nn.Sequential(\n",
    "            torch.nn.Linear(16 * 32 * 32, 1024),\n",
    "            torch.nn.ReLU(inplace=True),\n",
    "            torch.nn.Linear(1024, 1024),\n",
    "            torch.nn.ReLU(inplace=True),\n",
    "            torch.nn.Linear(1024, 128),\n",
    "            torch.nn.ReLU(inplace=True),\n",
    "            torch.nn.Linear(128, 64),\n",
    "            torch.nn.ReLU(inplace=True),\n",
    "            torch.nn.Linear(64, 2)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.layer1(x)\n",
    "        x = self.layer2(x)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = self.fc(x)\n",
    "        return x\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "class CustomLoss2(nn.Module):\n",
    "    def __init__(self) -> None:\n",
    "        super().__init__()\n",
    "    def forward(self, output, target):\n",
    "        res = -output.gather(dim=1, index=target.view(-1, 1))\n",
    "        res += torch.log(torch.exp(output).sum(dim=1).view(-1, 1))\n",
    "        res = res.mean()\n",
    "        return res\n",
    "    def forward(self, output, target, distance):\n",
    "        res = -output.gather(dim=1, index=target.view(-1, 1))\n",
    "        res += torch.log(torch.exp(output).sum(dim=1).view(-1, 1))\n",
    "        res = res.mean() * distance.mean()\n",
    "        return res\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "from typing import Callable, Optional\n",
    "from torch.nn import functional as F\n",
    "from torch.nn import _reduction as _Reduction\n",
    "from torch import Tensor\n",
    "class _Loss(nn.Module):\n",
    "    reduction: str\n",
    "\n",
    "    def __init__(self, size_average=None, reduce=None, reduction: str = 'mean') -> None:\n",
    "        super(_Loss, self).__init__()\n",
    "        if size_average is not None or reduce is not None:\n",
    "            self.reduction: str = _Reduction.legacy_get_string(size_average, reduce)\n",
    "        else:\n",
    "            self.reduction = reduction\n",
    "class _WeightedLoss(_Loss):\n",
    "    def __init__(self, weight: Optional[Tensor] = None, size_average=None, reduce=None, reduction: str = 'mean') -> None:\n",
    "        super(_WeightedLoss, self).__init__(size_average, reduce, reduction)\n",
    "        self.register_buffer('weight', weight)\n",
    "        self.weight: Optional[Tensor]\n",
    "class CELoss(_WeightedLoss): # 注意继承 nn.Module\n",
    "    __constants__ = ['ignore_index', 'reduction', 'label_smoothing']\n",
    "    ignore_index: int\n",
    "    label_smoothing: float\n",
    "\n",
    "    def __init__(self, weight: Optional[Tensor] = None, size_average=None, ignore_index: int = -100,\n",
    "                 reduce=None, reduction: str = 'mean', label_smoothing: float = 0.0) -> None:\n",
    "        super(CELoss, self).__init__(weight, size_average, reduce, reduction)\n",
    "        self.ignore_index = ignore_index\n",
    "        self.label_smoothing = label_smoothing\n",
    "\n",
    "    def forward(self, input: Tensor, target: Tensor, distance) -> Tensor:\n",
    "        return distance.mean() * F.cross_entropy(input, target, weight=self.weight,\n",
    "                               ignore_index=self.ignore_index, reduction=self.reduction,\n",
    "                               label_smoothing=self.label_smoothing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "model = MyNet().to(device)\n",
    "# define cost/loss & optimizer\n",
    "# Softmax is internally computed.\n",
    "# criterion = CELoss().to(device)\n",
    "criterion = CELoss().to(device)\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0001 cost = 0.693636894 trainacc: 50.26315789473684 testacc: 50.0 test_loss: 11.064018368721008\n",
      "Epoch: 0002 cost = 0.692377090 trainacc: 51.05263157894737 testacc: 50.0 test_loss: 11.06423169374466\n",
      "Epoch: 0003 cost = 0.692264497 trainacc: 53.421052631578945 testacc: 50.0 test_loss: 11.06311970949173\n",
      "Epoch: 0004 cost = 0.690714061 trainacc: 53.1578947368421 testacc: 50.0 test_loss: 11.064918637275696\n",
      "Epoch: 0005 cost = 0.691035748 trainacc: 54.21052631578947 testacc: 50.0 test_loss: 11.063293635845184\n",
      "Epoch: 0006 cost = 0.689290643 trainacc: 53.1578947368421 testacc: 50.0 test_loss: 11.066113233566284\n",
      "Epoch: 0007 cost = 0.689458787 trainacc: 54.73684210526316 testacc: 50.0 test_loss: 11.06419312953949\n",
      "Epoch: 0008 cost = 0.688580990 trainacc: 53.68421052631579 testacc: 50.0 test_loss: 11.06746256351471\n",
      "Epoch: 0009 cost = 0.688015044 trainacc: 53.94736842105263 testacc: 50.0 test_loss: 11.06718111038208\n",
      "Epoch: 0010 cost = 0.687945664 trainacc: 63.68421052631579 testacc: 51.31578947368421 test_loss: 11.061328530311584\n",
      "Epoch: 0011 cost = 0.687000453 trainacc: 63.68421052631579 testacc: 50.6578947368421 test_loss: 11.062784850597382\n",
      "Epoch: 0012 cost = 0.685911119 trainacc: 61.31578947368421 testacc: 51.31578947368421 test_loss: 11.063083171844482\n",
      "Epoch: 0013 cost = 0.685172737 trainacc: 60.26315789473684 testacc: 50.6578947368421 test_loss: 11.06409341096878\n",
      "Epoch: 0014 cost = 0.684857368 trainacc: 76.57894736842105 testacc: 50.6578947368421 test_loss: 11.062341570854187\n",
      "Epoch: 0015 cost = 0.683647633 trainacc: 73.94736842105263 testacc: 51.973684210526315 test_loss: 11.064007699489594\n",
      "Epoch: 0016 cost = 0.683058143 trainacc: 77.36842105263158 testacc: 51.973684210526315 test_loss: 11.063660860061646\n",
      "Epoch: 0017 cost = 0.682064235 trainacc: 86.57894736842105 testacc: 53.94736842105263 test_loss: 11.063396513462067\n",
      "Epoch: 0018 cost = 0.680223346 trainacc: 75.26315789473684 testacc: 51.31578947368421 test_loss: 11.065120935440063\n",
      "Epoch: 0019 cost = 0.679930925 trainacc: 71.84210526315789 testacc: 49.3421052631579 test_loss: 11.066874086856842\n",
      "Epoch: 0020 cost = 0.678624153 trainacc: 71.3157894736842 testacc: 49.3421052631579 test_loss: 11.06618857383728\n",
      "Epoch: 0021 cost = 0.677749276 trainacc: 81.05263157894737 testacc: 50.0 test_loss: 11.065155327320099\n",
      "Epoch: 0022 cost = 0.676485658 trainacc: 80.26315789473684 testacc: 51.973684210526315 test_loss: 11.066797494888306\n",
      "Epoch: 0023 cost = 0.676130831 trainacc: 83.94736842105263 testacc: 50.6578947368421 test_loss: 11.06716251373291\n",
      "Epoch: 0024 cost = 0.674214959 trainacc: 85.78947368421052 testacc: 51.31578947368421 test_loss: 11.065038621425629\n",
      "Epoch: 0025 cost = 0.672871470 trainacc: 78.6842105263158 testacc: 50.0 test_loss: 11.067928910255432\n",
      "Epoch: 0026 cost = 0.671977937 trainacc: 83.42105263157895 testacc: 50.0 test_loss: 11.068183302879333\n",
      "Epoch: 0027 cost = 0.670584738 trainacc: 73.94736842105263 testacc: 50.6578947368421 test_loss: 11.070265054702759\n",
      "Epoch: 0028 cost = 0.670121670 trainacc: 92.36842105263158 testacc: 50.0 test_loss: 11.068323194980621\n",
      "Epoch: 0029 cost = 0.668746293 trainacc: 84.21052631578948 testacc: 49.3421052631579 test_loss: 11.068822920322418\n",
      "Epoch: 0030 cost = 0.667000651 trainacc: 97.36842105263158 testacc: 52.63157894736842 test_loss: 11.068046033382416\n",
      "Epoch: 0031 cost = 0.666821361 trainacc: 96.84210526315789 testacc: 55.921052631578945 test_loss: 11.068895399570465\n",
      "Epoch: 0032 cost = 0.664340913 trainacc: 96.3157894736842 testacc: 51.973684210526315 test_loss: 11.069506108760834\n",
      "Epoch: 0033 cost = 0.663057566 trainacc: 97.89473684210526 testacc: 51.973684210526315 test_loss: 11.070878326892853\n",
      "Epoch: 0034 cost = 0.660959661 trainacc: 93.15789473684211 testacc: 50.6578947368421 test_loss: 11.072634994983673\n",
      "Epoch: 0035 cost = 0.660258889 trainacc: 95.78947368421052 testacc: 51.31578947368421 test_loss: 11.071832239627838\n",
      "Epoch: 0036 cost = 0.657671332 trainacc: 92.89473684210526 testacc: 51.31578947368421 test_loss: 11.074284672737122\n",
      "Epoch: 0037 cost = 0.656508982 trainacc: 93.6842105263158 testacc: 50.6578947368421 test_loss: 11.075059056282043\n",
      "Epoch: 0038 cost = 0.654618025 trainacc: 97.10526315789474 testacc: 50.0 test_loss: 11.073155522346497\n",
      "Epoch: 0039 cost = 0.652919710 trainacc: 97.63157894736842 testacc: 50.6578947368421 test_loss: 11.074151396751404\n",
      "Epoch: 0040 cost = 0.651231408 trainacc: 94.47368421052632 testacc: 50.6578947368421 test_loss: 11.077769756317139\n",
      "Epoch: 0041 cost = 0.648605883 trainacc: 97.36842105263158 testacc: 50.0 test_loss: 11.077477097511292\n",
      "Epoch: 0042 cost = 0.646481156 trainacc: 98.42105263157895 testacc: 52.63157894736842 test_loss: 11.075188100337982\n",
      "Epoch: 0043 cost = 0.643627167 trainacc: 96.05263157894737 testacc: 50.0 test_loss: 11.07852053642273\n",
      "Epoch: 0044 cost = 0.641276658 trainacc: 98.42105263157895 testacc: 50.6578947368421 test_loss: 11.075486719608307\n",
      "Epoch: 0045 cost = 0.637841642 trainacc: 97.63157894736842 testacc: 50.0 test_loss: 11.075583100318909\n",
      "Epoch: 0046 cost = 0.635322630 trainacc: 98.6842105263158 testacc: 49.3421052631579 test_loss: 11.07688820362091\n",
      "Epoch: 0047 cost = 0.632476687 trainacc: 98.42105263157895 testacc: 49.3421052631579 test_loss: 11.079878270626068\n",
      "Epoch: 0048 cost = 0.630168140 trainacc: 99.21052631578948 testacc: 50.6578947368421 test_loss: 11.07880848646164\n",
      "Epoch: 0049 cost = 0.627106667 trainacc: 98.42105263157895 testacc: 47.36842105263158 test_loss: 11.081768870353699\n",
      "Epoch: 0050 cost = 0.624055326 trainacc: 99.21052631578948 testacc: 49.3421052631579 test_loss: 11.08298522233963\n",
      "Epoch: 0051 cost = 0.620135307 trainacc: 97.36842105263158 testacc: 54.60526315789474 test_loss: 11.087627649307251\n",
      "Epoch: 0052 cost = 0.616181672 trainacc: 98.94736842105263 testacc: 54.60526315789474 test_loss: 11.086039543151855\n",
      "Epoch: 0053 cost = 0.612402320 trainacc: 98.94736842105263 testacc: 55.26315789473684 test_loss: 11.08877319097519\n",
      "Epoch: 0054 cost = 0.608350933 trainacc: 98.94736842105263 testacc: 53.94736842105263 test_loss: 11.089803576469421\n",
      "Epoch: 0055 cost = 0.602875650 trainacc: 99.21052631578948 testacc: 48.68421052631579 test_loss: 11.091052949428558\n",
      "Epoch: 0056 cost = 0.599319816 trainacc: 96.57894736842105 testacc: 49.3421052631579 test_loss: 11.096822082996368\n",
      "Epoch: 0057 cost = 0.594528973 trainacc: 100.0 testacc: 53.28947368421053 test_loss: 11.096774458885193\n",
      "Epoch: 0058 cost = 0.589682877 trainacc: 97.63157894736842 testacc: 50.0 test_loss: 11.108468174934387\n",
      "Epoch: 0059 cost = 0.582902133 trainacc: 100.0 testacc: 52.63157894736842 test_loss: 11.100978672504425\n",
      "Epoch: 0060 cost = 0.575989187 trainacc: 99.21052631578948 testacc: 48.026315789473685 test_loss: 11.10263991355896\n",
      "Epoch: 0061 cost = 0.569463015 trainacc: 99.73684210526316 testacc: 53.28947368421053 test_loss: 11.107474446296692\n",
      "Epoch: 0062 cost = 0.563788235 trainacc: 99.73684210526316 testacc: 52.63157894736842 test_loss: 11.105403006076813\n",
      "Epoch: 0063 cost = 0.554052830 trainacc: 97.89473684210526 testacc: 50.0 test_loss: 11.130551755428314\n",
      "Epoch: 0064 cost = 0.548350751 trainacc: 96.57894736842105 testacc: 48.026315789473685 test_loss: 11.144016981124878\n",
      "Epoch: 0065 cost = 0.540731311 trainacc: 95.78947368421052 testacc: 50.6578947368421 test_loss: 11.148585498332977\n",
      "Epoch: 0066 cost = 0.533325493 trainacc: 99.21052631578948 testacc: 48.68421052631579 test_loss: 11.131931722164154\n",
      "Epoch: 0067 cost = 0.523282647 trainacc: 87.36842105263158 testacc: 50.0 test_loss: 11.238847732543945\n",
      "Epoch: 0068 cost = 0.514932156 trainacc: 99.73684210526316 testacc: 51.31578947368421 test_loss: 11.136390388011932\n",
      "Epoch: 0069 cost = 0.503973901 trainacc: 100.0 testacc: 50.6578947368421 test_loss: 11.132038056850433\n",
      "Epoch: 0070 cost = 0.491898477 trainacc: 100.0 testacc: 49.3421052631579 test_loss: 11.139394283294678\n",
      "Epoch: 0071 cost = 0.481839836 trainacc: 99.73684210526316 testacc: 48.68421052631579 test_loss: 11.17078810930252\n",
      "Epoch: 0072 cost = 0.467260003 trainacc: 90.78947368421052 testacc: 50.0 test_loss: 11.321361184120178\n",
      "Epoch: 0073 cost = 0.457792729 trainacc: 98.42105263157895 testacc: 48.68421052631579 test_loss: 11.236281633377075\n",
      "Epoch: 0074 cost = 0.446085244 trainacc: 99.73684210526316 testacc: 51.31578947368421 test_loss: 11.193687558174133\n",
      "Epoch: 0075 cost = 0.433889270 trainacc: 87.89473684210526 testacc: 50.0 test_loss: 11.486583173274994\n",
      "Epoch: 0076 cost = 0.419270694 trainacc: 82.10526315789474 testacc: 50.0 test_loss: 11.660351783037186\n",
      "Epoch: 0077 cost = 0.403109789 trainacc: 100.0 testacc: 47.36842105263158 test_loss: 11.214712858200073\n",
      "Epoch: 0078 cost = 0.387262046 trainacc: 100.0 testacc: 47.36842105263158 test_loss: 11.235018074512482\n",
      "Epoch: 0079 cost = 0.371461719 trainacc: 100.0 testacc: 48.68421052631579 test_loss: 11.22601693868637\n",
      "Epoch: 0080 cost = 0.357234955 trainacc: 100.0 testacc: 46.05263157894737 test_loss: 11.240777492523193\n",
      "Epoch: 0081 cost = 0.342035681 trainacc: 100.0 testacc: 51.973684210526315 test_loss: 11.305098533630371\n",
      "Epoch: 0082 cost = 0.323734373 trainacc: 100.0 testacc: 49.3421052631579 test_loss: 11.28156965970993\n",
      "Epoch: 0083 cost = 0.313942611 trainacc: 100.0 testacc: 46.05263157894737 test_loss: 11.3888601064682\n",
      "Epoch: 0084 cost = 0.296247482 trainacc: 100.0 testacc: 51.31578947368421 test_loss: 11.367458999156952\n",
      "Epoch: 0085 cost = 0.277140021 trainacc: 100.0 testacc: 51.31578947368421 test_loss: 11.331823110580444\n",
      "Epoch: 0086 cost = 0.260443389 trainacc: 100.0 testacc: 48.68421052631579 test_loss: 11.496185779571533\n",
      "Epoch: 0087 cost = 0.246990368 trainacc: 100.0 testacc: 48.68421052631579 test_loss: 11.381094217300415\n",
      "Epoch: 0088 cost = 0.237452179 trainacc: 99.73684210526316 testacc: 49.3421052631579 test_loss: 11.814847707748413\n",
      "Epoch: 0089 cost = 0.221063435 trainacc: 100.0 testacc: 49.3421052631579 test_loss: 11.572991728782654\n",
      "Epoch: 0090 cost = 0.201666236 trainacc: 100.0 testacc: 47.36842105263158 test_loss: 11.423003017902374\n",
      "Epoch: 0091 cost = 0.189991415 trainacc: 100.0 testacc: 50.0 test_loss: 11.560113728046417\n",
      "Epoch: 0092 cost = 0.176251486 trainacc: 100.0 testacc: 50.0 test_loss: 11.950066566467285\n",
      "Epoch: 0093 cost = 0.166619897 trainacc: 100.0 testacc: 47.36842105263158 test_loss: 11.504818856716156\n",
      "Epoch: 0094 cost = 0.152592376 trainacc: 100.0 testacc: 50.6578947368421 test_loss: 11.66690468788147\n",
      "Epoch: 0095 cost = 0.141547889 trainacc: 100.0 testacc: 46.71052631578947 test_loss: 11.611482858657837\n",
      "Epoch: 0096 cost = 0.133871153 trainacc: 100.0 testacc: 43.421052631578945 test_loss: 11.57103681564331\n",
      "Epoch: 0097 cost = 0.121544145 trainacc: 100.0 testacc: 42.10526315789474 test_loss: 11.577705681324005\n",
      "Epoch: 0098 cost = 0.114251040 trainacc: 100.0 testacc: 51.973684210526315 test_loss: 11.75601476430893\n",
      "Epoch: 0099 cost = 0.112063780 trainacc: 100.0 testacc: 48.68421052631579 test_loss: 12.115603983402252\n",
      "Epoch: 0100 cost = 0.102188781 trainacc: 100.0 testacc: 51.31578947368421 test_loss: 11.824182152748108\n",
      "Epoch: 0101 cost = 0.094873101 trainacc: 100.0 testacc: 43.421052631578945 test_loss: 11.708951115608215\n",
      "Epoch: 0102 cost = 0.089349903 trainacc: 100.0 testacc: 42.76315789473684 test_loss: 11.71882939338684\n",
      "Epoch: 0103 cost = 0.081244163 trainacc: 100.0 testacc: 42.76315789473684 test_loss: 11.738364815711975\n",
      "Epoch: 0104 cost = 0.076543301 trainacc: 100.0 testacc: 44.078947368421055 test_loss: 11.755759418010712\n",
      "Epoch: 0105 cost = 0.069940485 trainacc: 100.0 testacc: 43.421052631578945 test_loss: 11.781116902828217\n",
      "Epoch: 0106 cost = 0.066899732 trainacc: 100.0 testacc: 42.76315789473684 test_loss: 11.79946893453598\n",
      "Epoch: 0107 cost = 0.062378500 trainacc: 100.0 testacc: 49.3421052631579 test_loss: 11.921659708023071\n",
      "Epoch: 0108 cost = 0.058590252 trainacc: 100.0 testacc: 51.31578947368421 test_loss: 12.133854508399963\n",
      "Epoch: 0109 cost = 0.055498604 trainacc: 100.0 testacc: 44.078947368421055 test_loss: 11.939704716205597\n",
      "Epoch: 0110 cost = 0.052510623 trainacc: 100.0 testacc: 43.421052631578945 test_loss: 11.915062844753265\n",
      "Epoch: 0111 cost = 0.049395189 trainacc: 100.0 testacc: 46.71052631578947 test_loss: 12.148973137140274\n",
      "Epoch: 0112 cost = 0.047301769 trainacc: 100.0 testacc: 42.10526315789474 test_loss: 11.957871496677399\n",
      "Epoch: 0113 cost = 0.044458676 trainacc: 100.0 testacc: 41.44736842105263 test_loss: 11.975547969341278\n",
      "Epoch: 0114 cost = 0.042664930 trainacc: 100.0 testacc: 44.078947368421055 test_loss: 11.997170627117157\n",
      "Epoch: 0115 cost = 0.039704811 trainacc: 100.0 testacc: 43.421052631578945 test_loss: 12.159882158041\n",
      "Epoch: 0116 cost = 0.038299941 trainacc: 100.0 testacc: 42.76315789473684 test_loss: 12.065917015075684\n",
      "Epoch: 0117 cost = 0.036422860 trainacc: 100.0 testacc: 41.44736842105263 test_loss: 12.100264132022858\n",
      "Epoch: 0118 cost = 0.034707244 trainacc: 100.0 testacc: 51.31578947368421 test_loss: 12.36342054605484\n",
      "Epoch: 0119 cost = 0.032962799 trainacc: 100.0 testacc: 43.421052631578945 test_loss: 12.084781229496002\n",
      "Epoch: 0120 cost = 0.032466587 trainacc: 100.0 testacc: 42.10526315789474 test_loss: 12.084557294845581\n",
      "Learning finished\n"
     ]
    }
   ],
   "source": [
    "total_batch = len(data_loader_train)\n",
    "\n",
    "for epoch in range(training_epochs):\n",
    "    model.train()\n",
    "    avg_cost = 0\n",
    "\n",
    "    # for X, Y in data_loader_train:\n",
    "    #     X = torch.autograd.Variable(X).to(device).float()\n",
    "    #     Y = Y.to(device)\n",
    "\n",
    "    #     optimizer.zero_grad()\n",
    "    #     hypothesis = model(X)\n",
    "    #     cost = criterion(hypothesis, Y)\n",
    "    #     cost.backward()\n",
    "    #     optimizer.step()\n",
    "\n",
    "    #     avg_cost += cost / total_batch\n",
    "    # model.train()\n",
    "    train_loss = 0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    for batch_idx, (inputs, targets) in enumerate(data_loader_train):\n",
    "        distance = targets[:,1].to(device).float()\n",
    "        targets = targets[:,0]\n",
    "        inputs, targets = inputs.to(device).float(), targets.to(device).to(torch.int64)\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, targets, distance)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        train_loss += loss.item()\n",
    "        _, predicted = outputs.max(1)\n",
    "        total += targets.size(0)\n",
    "        correct += predicted.eq(targets).sum().item()\n",
    "        avg_cost += loss / total_batch\n",
    "\n",
    "    \n",
    "    # if avg_cost < 0.1:\n",
    "    #     break\n",
    "    model.eval()\n",
    "    # with torch.no_grad():\n",
    "    #     for X_test, Y_test in data_loader_test:\n",
    "    #         X_test = X_test.to(device).float()\n",
    "    #         Y_test = Y_test.to(device)\n",
    "\n",
    "    #     prediction = model(X_test)\n",
    "    #     correct_prediction = torch.argmax(prediction, 1) == Y_test\n",
    "    #     accuracy = correct_prediction.float().mean()\n",
    "    test_loss = 0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for batch_idx, (inputs, targets) in enumerate(data_loader_train):\n",
    "            distance = targets[:,1].to(device).float()\n",
    "            targets = targets[:,0]\n",
    "            inputs, targets = inputs.to(device).float(), targets.to(device).to(torch.int64)\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, targets, distance)\n",
    "\n",
    "            test_loss += loss.item()\n",
    "            _, predicted = outputs.max(1)\n",
    "            total += targets.size(0)\n",
    "            correct += predicted.eq(targets).sum().item()\n",
    "    trainacc = 100.*correct/total\n",
    "    test_loss = 0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for batch_idx, (inputs, targets) in enumerate(data_loader_test):\n",
    "            distance = targets[:,1].to(device).float()\n",
    "            targets = targets[:,0]\n",
    "            inputs, targets = inputs.to(device).float(), targets.to(device).to(torch.int64)\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, targets, distance)\n",
    "\n",
    "            test_loss += loss.item()\n",
    "            _, predicted = outputs.max(1)\n",
    "            total += targets.size(0)\n",
    "            correct += predicted.eq(targets).sum().item()\n",
    "    testacc = 100.*correct/total\n",
    "    print('Epoch:', '%04d' % (epoch + 1), 'cost =', '{:.9f}'.format(avg_cost), 'trainacc:', trainacc, 'testacc:', testacc, 'test_loss:', test_loss)\n",
    "\n",
    "print('Learning finished')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1, 0, 0, 1, 1, 0, 1, 0, 1, 0], device='cuda:0') tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0], device='cuda:0')\n",
      "tensor([1, 1, 0, 1, 1, 0, 0, 1, 1, 1], device='cuda:0') tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0], device='cuda:0')\n",
      "testacc: 40.0\n"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    for batch_idx, (inputs, targets) in enumerate(data_loader_test):\n",
    "        if batch_idx >= 2: break\n",
    "        distance = targets[:,1].to(device).float()\n",
    "        targets = targets[:,0]\n",
    "        inputs, targets = inputs.to(device).float(), targets.to(device).to(torch.int64)\n",
    "        outputs = model(inputs)\n",
    "        _, predicted = outputs.max(1)\n",
    "        total += targets.size(0)\n",
    "        correct += predicted.eq(targets).sum().item()\n",
    "        print(torch.argmax(outputs, 1), targets)\n",
    "    testacc = 100.*correct/total\n",
    "    print('testacc:', testacc)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "vscode": {
   "interpreter": {
    "hash": "1d28dcb1746f058774bc7e3103f8fd674f9a46f28636659ba6a6fdaf0b17e1a8"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
