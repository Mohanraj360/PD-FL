{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "# input_data shape\n",
    "Input: (batch_size, in_channel, width, height)\n",
    "# conv layer\n",
    "class torch.nn.Conv2d(in_channels, out_channels, kernel_size, stride=1, padding=0, dilation=1, groups=1, bias=True)\n",
    "input: (Batch_size, C_in, H_in, W_in)\n",
    "output: (Batch_size, C_out, H_out, W_out)\n",
    "\n",
    "weight(tensor): (out_channels, in_channels,kernel_size)\n",
    "bias(tensor): (out_channel)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "from itertools import product\n",
    "\n",
    "import time\n",
    "import numpy as np\n",
    "from sklearn import datasets\n",
    "from scipy.stats import multivariate_normal as mvn\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from ripser import Rips\n",
    "from persim import PersistenceImager\n",
    "\n",
    "import os\n",
    "import math\n",
    "\n",
    "import seaborn\n",
    "import pandas as pd\n",
    "import torch\n",
    "import random\n",
    "from torch import nn\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import persim\n",
    "\n",
    "import re\n",
    "import cv2\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "# for reproducibility\n",
    "random.seed(111)\n",
    "torch.manual_seed(777)\n",
    "if device == 'cuda':\n",
    "    torch.cuda.manual_seed_all(777)\n",
    "# parameters\n",
    "learning_rate = 0.001\n",
    "training_epochs = 450\n",
    "batchsize = 25\n",
    "testbatchsize = 10\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "# dir = os.listdir(\"./metric\")\n",
    "# data = []\n",
    "# a = []\n",
    "# for metric in dir:\n",
    "#     a = re.findall(\"\\d+\\.?\\d*\", metric)\n",
    "#     data.append([np.loadtxt(\"./metric/\"+metric), metric])\n",
    "#     # print(a[-2])\n",
    "#     print(metric[-2])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 2, 3])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = np.array([1,2,3])\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "class My_dataset(Dataset):\n",
    "    def __init__(self, train):\n",
    "        super().__init__()\n",
    "        dirtrain = os.listdir(\"./grids_single_trainset\")\n",
    "        dirtest = os.listdir(\"./grids_single_testset\")\n",
    "        data = []\n",
    "        \n",
    "        if train:\n",
    "            dir = dirtrain\n",
    "            path = \"./grids_single_trainset/\"\n",
    "        else:\n",
    "            dir = dirtest\n",
    "            path = \"./grids_single_testset/\"\n",
    "\n",
    "        T_normal = []\n",
    "        T_attack = []\n",
    "        for metric in dir[0:4]:\n",
    "            dgm = []\n",
    "            grid = pd.DataFrame(np.loadtxt(path+metric))\n",
    "            for i in range(grid.shape[0]):\n",
    "                for j in range(grid.shape[1]):\n",
    "                    if grid[i][j] > 0:\n",
    "                        dgm.append([i,j])\n",
    "            T_normal.append(dgm)\n",
    "        for metric in dir[-4:]:\n",
    "            dgm = []\n",
    "            grid = pd.DataFrame(np.loadtxt(path+metric))\n",
    "            for i in range(grid.shape[0]):\n",
    "                for j in range(grid.shape[1]):\n",
    "                    if grid[i][j] > 0:\n",
    "                        dgm.append([i,j])\n",
    "            T_attack.append(dgm)\n",
    "\n",
    "        print(len(T_attack), len(T_normal))\n",
    "        \n",
    "        sample = []\n",
    "        distance = 1\n",
    "        for metric in dir:\n",
    "            sample.append([np.loadtxt(path+metric), metric])\n",
    "            label = int(metric[0:len(\"h_vr_metric-single-mnist_moreFC=mnist_moreFC_attack\")]== \"h_vr_metric-single-mnist_moreFC=mnist_moreFC_attack\")\n",
    "            if (label == 0):\n",
    "                distance_bottleneck, matching = persim.bottleneck(sample[len(sample)-1][0], T_normal[len(sample)-1], matching=True)\n",
    "            else:\n",
    "                distance_bottleneck, matching = persim.bottleneck(sample[len(sample)-1][0], T_attack[len(sample)-1], matching=True)\n",
    "            distance += distance_bottleneck\n",
    "            if len(sample) == 4:\n",
    "                res = cv2.merge([i[0] for i in sample])\n",
    "                res = np.transpose(res,(2,0,1))\n",
    "                data.append([res, np.array((label,1/(1+math.exp(math.log(distance)))))])\n",
    "                sample = []\n",
    "\n",
    "        self.x = [item[0] for item in data]\n",
    "        self.y = [item[1] for item in data]\n",
    "        # self.y = [int(re.findall(\"\\d+\\.?\\d*\", item[1])[0]) for item in data]\n",
    "        self.src,  self.trg = [], []\n",
    "        for i in range(len(data)):\n",
    "            self.src.append(self.x[i])\n",
    "            self.trg.append(self.y[i])\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        return self.src[index], self.trg[index]\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.src)\n",
    "\n",
    " # 或者return len(self.trg), src和trg长度一样\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4 4\n",
      "4 4\n",
      "train\n",
      "0\n",
      "torch.Size([25, 4, 128, 128])\n",
      "tensor([[1.0000e+00, 1.2839e-04],\n",
      "        [0.0000e+00, 1.2771e-03],\n",
      "        [1.0000e+00, 1.3543e-04],\n",
      "        [0.0000e+00, 2.0113e-04],\n",
      "        [0.0000e+00, 1.7599e-04],\n",
      "        [1.0000e+00, 8.1656e-05],\n",
      "        [0.0000e+00, 1.3699e-02],\n",
      "        [1.0000e+00, 1.1521e-04],\n",
      "        [0.0000e+00, 3.0600e-04],\n",
      "        [1.0000e+00, 1.4004e-04],\n",
      "        [1.0000e+00, 9.6307e-05],\n",
      "        [0.0000e+00, 2.9949e-04],\n",
      "        [0.0000e+00, 7.4019e-04],\n",
      "        [1.0000e+00, 1.0720e-04],\n",
      "        [0.0000e+00, 5.0251e-04],\n",
      "        [1.0000e+00, 7.6118e-05],\n",
      "        [1.0000e+00, 1.5401e-04],\n",
      "        [1.0000e+00, 9.8639e-05],\n",
      "        [0.0000e+00, 1.9026e-04],\n",
      "        [0.0000e+00, 5.6275e-04],\n",
      "        [0.0000e+00, 3.4329e-04],\n",
      "        [1.0000e+00, 1.0274e-04],\n",
      "        [0.0000e+00, 1.7544e-03],\n",
      "        [1.0000e+00, 7.8043e-05],\n",
      "        [1.0000e+00, 7.7068e-05]], dtype=torch.float64)\n",
      "1\n",
      "torch.Size([25, 4, 128, 128])\n",
      "tensor([[0.0000e+00, 1.8285e-04],\n",
      "        [1.0000e+00, 8.9989e-05],\n",
      "        [0.0000e+00, 1.9286e-04],\n",
      "        [1.0000e+00, 7.5191e-05],\n",
      "        [0.0000e+00, 3.1990e-04],\n",
      "        [1.0000e+00, 8.5620e-05],\n",
      "        [0.0000e+00, 1.9554e-04],\n",
      "        [1.0000e+00, 9.9433e-05],\n",
      "        [0.0000e+00, 2.1659e-04],\n",
      "        [0.0000e+00, 2.0040e-03],\n",
      "        [0.0000e+00, 3.7037e-04],\n",
      "        [0.0000e+00, 2.1997e-04],\n",
      "        [0.0000e+00, 2.5595e-04],\n",
      "        [0.0000e+00, 1.6000e-04],\n",
      "        [0.0000e+00, 6.6979e-04],\n",
      "        [0.0000e+00, 7.8125e-04],\n",
      "        [0.0000e+00, 2.4697e-04],\n",
      "        [0.0000e+00, 4.3975e-04],\n",
      "        [1.0000e+00, 1.2974e-04],\n",
      "        [0.0000e+00, 2.6069e-04],\n",
      "        [1.0000e+00, 1.0910e-04],\n",
      "        [1.0000e+00, 1.3847e-04],\n",
      "        [1.0000e+00, 1.5026e-04],\n",
      "        [1.0000e+00, 8.0067e-05],\n",
      "        [1.0000e+00, 9.0650e-05]], dtype=torch.float64)\n",
      "2\n",
      "torch.Size([25, 4, 128, 128])\n",
      "tensor([[0.0000e+00, 3.8037e-04],\n",
      "        [0.0000e+00, 3.1279e-04],\n",
      "        [1.0000e+00, 9.4827e-05],\n",
      "        [0.0000e+00, 5.2110e-04],\n",
      "        [0.0000e+00, 1.1710e-03],\n",
      "        [0.0000e+00, 1.9829e-04],\n",
      "        [1.0000e+00, 9.2001e-05],\n",
      "        [1.0000e+00, 1.0361e-04],\n",
      "        [1.0000e+00, 1.0106e-04],\n",
      "        [0.0000e+00, 1.0040e-03],\n",
      "        [0.0000e+00, 2.8727e-04],\n",
      "        [0.0000e+00, 9.3721e-04],\n",
      "        [0.0000e+00, 6.9444e-03],\n",
      "        [0.0000e+00, 2.7071e-04],\n",
      "        [0.0000e+00, 1.0811e-03],\n",
      "        [1.0000e+00, 9.4104e-05],\n",
      "        [1.0000e+00, 8.6824e-05],\n",
      "        [1.0000e+00, 1.2326e-04],\n",
      "        [1.0000e+00, 9.2691e-05],\n",
      "        [1.0000e+00, 1.3111e-04],\n",
      "        [0.0000e+00, 4.0209e-04],\n",
      "        [1.0000e+00, 1.2706e-04],\n",
      "        [0.0000e+00, 5.4113e-04],\n",
      "        [0.0000e+00, 1.6762e-04],\n",
      "        [1.0000e+00, 1.1310e-04]], dtype=torch.float64)\n",
      "3\n",
      "torch.Size([25, 4, 128, 128])\n",
      "tensor([[1.0000e+00, 1.1007e-04],\n",
      "        [1.0000e+00, 8.6218e-05],\n",
      "        [0.0000e+00, 2.2346e-04],\n",
      "        [1.0000e+00, 1.0190e-04],\n",
      "        [1.0000e+00, 1.4669e-04],\n",
      "        [1.0000e+00, 7.7552e-05],\n",
      "        [0.0000e+00, 7.0323e-04],\n",
      "        [1.0000e+00, 1.1967e-04],\n",
      "        [1.0000e+00, 1.4164e-04],\n",
      "        [1.0000e+00, 8.7439e-05],\n",
      "        [0.0000e+00, 3.3512e-04],\n",
      "        [0.0000e+00, 1.4045e-03],\n",
      "        [0.0000e+00, 1.6184e-04],\n",
      "        [0.0000e+00, 3.4965e-03],\n",
      "        [0.0000e+00, 4.6512e-03],\n",
      "        [1.0000e+00, 8.4449e-05],\n",
      "        [1.0000e+00, 1.4846e-04],\n",
      "        [1.0000e+00, 8.8696e-05],\n",
      "        [0.0000e+00, 4.8520e-04],\n",
      "        [0.0000e+00, 1.8051e-04],\n",
      "        [1.0000e+00, 8.0590e-05],\n",
      "        [0.0000e+00, 6.3939e-04],\n",
      "        [0.0000e+00, 2.4272e-04],\n",
      "        [0.0000e+00, 5.8617e-04],\n",
      "        [1.0000e+00, 1.1106e-04]], dtype=torch.float64)\n",
      "4\n",
      "torch.Size([25, 4, 128, 128])\n",
      "tensor([[1.0000e+00, 8.3309e-05],\n",
      "        [0.0000e+00, 1.8525e-04],\n",
      "        [1.0000e+00, 1.5795e-04],\n",
      "        [1.0000e+00, 1.0814e-04],\n",
      "        [1.0000e+00, 1.3396e-04],\n",
      "        [1.0000e+00, 9.7064e-05],\n",
      "        [1.0000e+00, 1.2204e-04],\n",
      "        [1.0000e+00, 1.4497e-04],\n",
      "        [0.0000e+00, 3.5186e-04],\n",
      "        [1.0000e+00, 1.0537e-04],\n",
      "        [0.0000e+00, 8.7873e-04],\n",
      "        [1.0000e+00, 1.5211e-04],\n",
      "        [1.0000e+00, 1.3252e-04],\n",
      "        [0.0000e+00, 2.3079e-04],\n",
      "        [0.0000e+00, 2.3463e-04],\n",
      "        [0.0000e+00, 2.9326e-04],\n",
      "        [1.0000e+00, 7.8539e-05],\n",
      "        [1.0000e+00, 1.1853e-04],\n",
      "        [0.0000e+00, 6.1162e-04],\n",
      "        [1.0000e+00, 9.5561e-05],\n",
      "        [0.0000e+00, 1.6372e-04],\n",
      "        [0.0000e+00, 1.7822e-04],\n",
      "        [1.0000e+00, 7.5652e-05],\n",
      "        [1.0000e+00, 8.9338e-05],\n",
      "        [1.0000e+00, 1.1740e-04]], dtype=torch.float64)\n",
      "5\n",
      "torch.Size([25, 4, 128, 128])\n",
      "tensor([[0.0000e+00, 2.0704e-04],\n",
      "        [1.0000e+00, 7.9551e-05],\n",
      "        [1.0000e+00, 9.1320e-05],\n",
      "        [0.0000e+00, 3.6088e-04],\n",
      "        [1.0000e+00, 9.3392e-05],\n",
      "        [1.0000e+00, 1.3693e-04],\n",
      "        [1.0000e+00, 1.0628e-04],\n",
      "        [1.0000e+00, 7.4736e-05],\n",
      "        [0.0000e+00, 1.8772e-04],\n",
      "        [1.0000e+00, 1.5596e-04],\n",
      "        [1.0000e+00, 8.2200e-05],\n",
      "        [0.0000e+00, 2.3861e-04],\n",
      "        [0.0000e+00, 4.5393e-04],\n",
      "        [0.0000e+00, 2.8011e-03],\n",
      "        [1.0000e+00, 1.4329e-04],\n",
      "        [0.0000e+00, 2.7601e-04],\n",
      "        [0.0000e+00, 1.6565e-04],\n",
      "        [0.0000e+00, 2.2707e-04],\n",
      "        [0.0000e+00, 2.1013e-04],\n",
      "        [1.0000e+00, 1.2577e-04],\n",
      "        [1.0000e+00, 1.0448e-04],\n",
      "        [1.0000e+00, 8.5030e-05],\n",
      "        [1.0000e+00, 7.6590e-05],\n",
      "        [0.0000e+00, 4.2644e-04],\n",
      "        [1.0000e+00, 7.9042e-05]], dtype=torch.float64)\n",
      "6\n",
      "torch.Size([25, 4, 128, 128])\n",
      "tensor([[1.0000e+00, 1.1414e-04],\n",
      "        [0.0000e+00, 2.8153e-04],\n",
      "        [1.0000e+00, 1.0024e-04],\n",
      "        [0.0000e+00, 2.1331e-04],\n",
      "        [0.0000e+00, 4.1391e-04],\n",
      "        [0.0000e+00, 3.9093e-04],\n",
      "        [0.0000e+00, 1.5601e-03],\n",
      "        [0.0000e+00, 1.6964e-04],\n",
      "        [1.0000e+00, 8.1119e-05],\n",
      "        [1.0000e+00, 1.1207e-04],\n",
      "        [1.0000e+00, 1.2450e-04],\n",
      "        [1.0000e+00, 9.7833e-05],\n",
      "        [0.0000e+00, 8.2713e-04],\n",
      "        [1.0000e+00, 1.2085e-04],\n",
      "        [0.0000e+00, 1.7170e-04],\n",
      "        [0.0000e+00, 2.0404e-04],\n",
      "        [0.0000e+00, 2.5138e-04],\n",
      "        [1.0000e+00, 1.1629e-04],\n",
      "        [0.0000e+00, 2.6560e-04],\n",
      "        [1.0000e+00, 8.2751e-05],\n",
      "        [1.0000e+00, 8.3875e-05],\n",
      "        [0.0000e+00, 3.2733e-04],\n",
      "        [1.0000e+00, 8.8063e-05],\n",
      "        [0.0000e+00, 1.7382e-04],\n",
      "        [0.0000e+00, 2.3364e-03]], dtype=torch.float64)\n",
      "7\n",
      "torch.Size([1, 4, 128, 128])\n",
      "tensor([[0.0000, 0.0005]], dtype=torch.float64)\n",
      "test\n",
      "0\n",
      "torch.Size([10, 4, 128, 128])\n",
      "tensor([[0.0000e+00, 3.5211e-03],\n",
      "        [0.0000e+00, 1.7637e-03],\n",
      "        [0.0000e+00, 1.1933e-03],\n",
      "        [1.0000e+00, 8.7835e-04],\n",
      "        [0.0000e+00, 1.3021e-03],\n",
      "        [1.0000e+00, 5.6433e-04],\n",
      "        [0.0000e+00, 2.3419e-03],\n",
      "        [0.0000e+00, 1.5699e-03],\n",
      "        [1.0000e+00, 6.6644e-04],\n",
      "        [1.0000e+00, 7.5786e-04]], dtype=torch.float64)\n",
      "1\n",
      "torch.Size([10, 4, 128, 128])\n",
      "tensor([[0.0000e+00, 2.8249e-03],\n",
      "        [0.0000e+00, 4.7170e-03],\n",
      "        [1.0000e+00, 7.0922e-04],\n",
      "        [0.0000e+00, 9.5420e-04],\n",
      "        [0.0000e+00, 1.0225e-03],\n",
      "        [0.0000e+00, 1.1013e-03],\n",
      "        [1.0000e+00, 4.3197e-04],\n",
      "        [1.0000e+00, 4.6860e-04],\n",
      "        [1.0000e+00, 5.1203e-04],\n",
      "        [1.0000e+00, 8.1367e-04]], dtype=torch.float64)\n",
      "2\n",
      "torch.Size([8, 4, 128, 128])\n",
      "tensor([[1.0000e+00, 4.8936e-04],\n",
      "        [0.0000e+00, 1.3889e-02],\n",
      "        [1.0000e+00, 6.2854e-04],\n",
      "        [0.0000e+00, 7.0423e-03],\n",
      "        [1.0000e+00, 4.4954e-04],\n",
      "        [0.0000e+00, 2.0121e-03],\n",
      "        [1.0000e+00, 5.3691e-04],\n",
      "        [1.0000e+00, 5.9471e-04]], dtype=torch.float64)\n"
     ]
    }
   ],
   "source": [
    "data_tf = transforms.Compose(\n",
    "    [transforms.ToTensor(),\n",
    "     transforms.Normalize([0.5], [0.5])])\n",
    "     \n",
    "data_train = My_dataset(train=True)\n",
    "data_test = My_dataset(train=False)\n",
    "data_loader_train = DataLoader(data_train, batch_size=batchsize, shuffle=True)\n",
    "data_loader_test = DataLoader(data_test, batch_size=testbatchsize, shuffle=True)\n",
    "\n",
    "\n",
    "# i_batch的多少根据batch size和def __len__(self)返回的长度确定\n",
    "# batch_data返回的值根据def __getitem__(self, index)来确定\n",
    "# 对训练集：(不太清楚enumerate返回什么的时候就多print试试)\n",
    "print(\"train\")\n",
    "for i_batch, batch_data in enumerate(data_loader_train):\n",
    "    print(i_batch)  # 打印batch编号\n",
    "    print(batch_data[0].shape)  # 打印该batch里面src\n",
    "    print(batch_data[1])  # 打印该batch里面trg\n",
    "# # 对测试集：（下面的语句也可以）\n",
    "print(\"test\")\n",
    "for i_batch, batch_data in enumerate(data_loader_test):\n",
    "    print(i_batch)  # 打印batch编号\n",
    "    print(batch_data[0].shape)  # 打印该batch里面src\n",
    "    print(batch_data[1])  # 打印该batch里面trg\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "class MyNet(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(MyNet, self).__init__()\n",
    "        self.layer1 = torch.nn.Sequential(\n",
    "            torch.nn.Conv2d(4, 16, kernel_size=64),\n",
    "            torch.nn.BatchNorm2d(16),\n",
    "            torch.nn.ReLU(inplace=True)\n",
    "        )\n",
    "\n",
    "        self.layer2 = torch.nn.Sequential(\n",
    "            torch.nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        )\n",
    "\n",
    "        self.fc = torch.nn.Sequential(\n",
    "            torch.nn.Linear(16 * 32 * 32, 1024),\n",
    "            torch.nn.ReLU(inplace=True),\n",
    "            torch.nn.Linear(1024, 1024),\n",
    "            torch.nn.ReLU(inplace=True),\n",
    "            torch.nn.Linear(1024, 128),\n",
    "            torch.nn.ReLU(inplace=True),\n",
    "            torch.nn.Linear(128, 64),\n",
    "            torch.nn.ReLU(inplace=True),\n",
    "            torch.nn.Linear(64, 2)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.layer1(x)\n",
    "        x = self.layer2(x)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = self.fc(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "model = MyNet().to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "class CustomLoss2(nn.Module):\n",
    "    def __init__(self) -> None:\n",
    "        super().__init__()\n",
    "    def forward(self, output, target):\n",
    "        res = -output.gather(dim=1, index=target.view(-1, 1))\n",
    "        res += torch.log(torch.exp(output).sum(dim=1).view(-1, 1))\n",
    "        res = res.mean()\n",
    "        return res\n",
    "    def forward(self, output, target, distance):\n",
    "        res = -output.gather(dim=1, index=target.view(-1, 1))\n",
    "        res += torch.log(torch.exp(output).sum(dim=1).view(-1, 1))\n",
    "        res = res.mean() * distance.mean()\n",
    "        return res\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "from typing import Callable, Optional\n",
    "from torch.nn import functional as F\n",
    "from torch.nn import _reduction as _Reduction\n",
    "from torch import Tensor\n",
    "class _Loss(nn.Module):\n",
    "    reduction: str\n",
    "\n",
    "    def __init__(self, size_average=None, reduce=None, reduction: str = 'mean') -> None:\n",
    "        super(_Loss, self).__init__()\n",
    "        if size_average is not None or reduce is not None:\n",
    "            self.reduction: str = _Reduction.legacy_get_string(size_average, reduce)\n",
    "        else:\n",
    "            self.reduction = reduction\n",
    "class _WeightedLoss(_Loss):\n",
    "    def __init__(self, weight: Optional[Tensor] = None, size_average=None, reduce=None, reduction: str = 'mean') -> None:\n",
    "        super(_WeightedLoss, self).__init__(size_average, reduce, reduction)\n",
    "        self.register_buffer('weight', weight)\n",
    "        self.weight: Optional[Tensor]\n",
    "class CELoss(_WeightedLoss): # 注意继承 nn.Module\n",
    "    __constants__ = ['ignore_index', 'reduction', 'label_smoothing']\n",
    "    ignore_index: int\n",
    "    label_smoothing: float\n",
    "\n",
    "    def __init__(self, weight: Optional[Tensor] = None, size_average=None, ignore_index: int = -100,\n",
    "                 reduce=None, reduction: str = 'mean', label_smoothing: float = 0.0) -> None:\n",
    "        super(CELoss, self).__init__(weight, size_average, reduce, reduction)\n",
    "        self.ignore_index = ignore_index\n",
    "        self.label_smoothing = label_smoothing\n",
    "\n",
    "    def forward(self, input: Tensor, target: Tensor, distance) -> Tensor:\n",
    "        return distance.mean() * F.cross_entropy(input, target, weight=self.weight,\n",
    "                               ignore_index=self.ignore_index, reduction=self.reduction,\n",
    "                               label_smoothing=self.label_smoothing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "# define cost/loss & optimizer\n",
    "# Softmax is internally computed.\n",
    "# criterion = CELoss().to(device)\n",
    "criterion = CELoss().to(device)\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0001 cost = 0.206325144 trainacc: 50.0 testacc: 50.0\n",
      "Epoch: 0002 cost = 0.208161384 trainacc: 50.0 testacc: 50.0\n",
      "Epoch: 0003 cost = 0.208320558 trainacc: 50.0 testacc: 50.0\n",
      "Epoch: 0004 cost = 0.208006114 trainacc: 50.0 testacc: 50.0\n",
      "Epoch: 0005 cost = 0.206213757 trainacc: 50.0 testacc: 50.0\n",
      "Epoch: 0006 cost = 0.209133327 trainacc: 50.0 testacc: 50.0\n",
      "Epoch: 0007 cost = 0.208686307 trainacc: 50.0 testacc: 50.0\n",
      "Epoch: 0008 cost = 0.208418414 trainacc: 50.0 testacc: 50.0\n",
      "Epoch: 0009 cost = 0.208475202 trainacc: 50.0 testacc: 50.0\n",
      "Epoch: 0010 cost = 0.208987057 trainacc: 50.0 testacc: 50.0\n",
      "Epoch: 0011 cost = 0.207747176 trainacc: 50.0 testacc: 50.0\n",
      "Epoch: 0012 cost = 0.208426699 trainacc: 50.0 testacc: 50.0\n",
      "Epoch: 0013 cost = 0.210691914 trainacc: 50.0 testacc: 50.0\n",
      "Epoch: 0014 cost = 0.208645061 trainacc: 50.0 testacc: 50.0\n",
      "Epoch: 0015 cost = 0.208499908 trainacc: 50.0 testacc: 50.0\n",
      "Epoch: 0016 cost = 0.208352149 trainacc: 50.0 testacc: 50.0\n",
      "Epoch: 0017 cost = 0.208819762 trainacc: 50.0 testacc: 50.0\n",
      "Epoch: 0018 cost = 0.208176166 trainacc: 50.0 testacc: 50.0\n",
      "Epoch: 0019 cost = 0.207376018 trainacc: 50.0 testacc: 50.0\n",
      "Epoch: 0020 cost = 0.208292902 trainacc: 50.0 testacc: 50.0\n",
      "Epoch: 0021 cost = 0.208350062 trainacc: 50.0 testacc: 50.0\n",
      "Epoch: 0022 cost = 0.208585978 trainacc: 50.0 testacc: 50.0\n",
      "Epoch: 0023 cost = 0.208008230 trainacc: 50.0 testacc: 50.0\n",
      "Epoch: 0024 cost = 0.206665576 trainacc: 50.0 testacc: 50.0\n",
      "Epoch: 0025 cost = 0.206158906 trainacc: 50.0 testacc: 50.0\n",
      "Epoch: 0026 cost = 0.207238510 trainacc: 50.0 testacc: 50.0\n",
      "Epoch: 0027 cost = 0.207605988 trainacc: 50.0 testacc: 50.0\n",
      "Epoch: 0028 cost = 0.207722336 trainacc: 50.0 testacc: 50.0\n",
      "Epoch: 0029 cost = 0.205868408 trainacc: 50.0 testacc: 50.0\n",
      "Epoch: 0030 cost = 0.207687438 trainacc: 50.0 testacc: 50.0\n",
      "Epoch: 0031 cost = 0.207644492 trainacc: 50.0 testacc: 50.0\n",
      "Epoch: 0032 cost = 0.208230734 trainacc: 50.0 testacc: 50.0\n",
      "Epoch: 0033 cost = 0.206747025 trainacc: 50.0 testacc: 50.0\n",
      "Epoch: 0034 cost = 0.206909150 trainacc: 50.0 testacc: 50.0\n",
      "Epoch: 0035 cost = 0.206161335 trainacc: 50.0 testacc: 50.0\n",
      "Epoch: 0036 cost = 0.205945551 trainacc: 50.0 testacc: 50.0\n",
      "Epoch: 0037 cost = 0.207629159 trainacc: 50.0 testacc: 50.0\n",
      "Epoch: 0038 cost = 0.207170278 trainacc: 50.0 testacc: 50.0\n",
      "Epoch: 0039 cost = 0.207446605 trainacc: 50.0 testacc: 50.0\n",
      "Epoch: 0040 cost = 0.207330838 trainacc: 50.0 testacc: 50.0\n",
      "Epoch: 0041 cost = 0.205994278 trainacc: 50.0 testacc: 50.0\n",
      "Epoch: 0042 cost = 0.207706764 trainacc: 50.0 testacc: 50.0\n",
      "Epoch: 0043 cost = 0.206713289 trainacc: 50.0 testacc: 50.0\n",
      "Epoch: 0044 cost = 0.206835181 trainacc: 50.0 testacc: 50.0\n",
      "Epoch: 0045 cost = 0.206208646 trainacc: 50.0 testacc: 50.0\n",
      "Epoch: 0046 cost = 0.206639394 trainacc: 50.0 testacc: 50.0\n",
      "Epoch: 0047 cost = 0.206551209 trainacc: 50.0 testacc: 50.0\n",
      "Epoch: 0048 cost = 0.206856579 trainacc: 50.0 testacc: 50.0\n",
      "Epoch: 0049 cost = 0.206532493 trainacc: 50.0 testacc: 50.0\n",
      "Epoch: 0050 cost = 0.207485601 trainacc: 50.0 testacc: 50.0\n",
      "Epoch: 0051 cost = 0.207950398 trainacc: 50.0 testacc: 50.0\n",
      "Epoch: 0052 cost = 0.208091915 trainacc: 50.0 testacc: 50.0\n",
      "Epoch: 0053 cost = 0.206581831 trainacc: 50.0 testacc: 50.0\n",
      "Epoch: 0054 cost = 0.207646653 trainacc: 50.0 testacc: 50.0\n",
      "Epoch: 0055 cost = 0.207186282 trainacc: 50.0 testacc: 50.0\n",
      "Epoch: 0056 cost = 0.207229078 trainacc: 50.0 testacc: 50.0\n",
      "Epoch: 0057 cost = 0.210971460 trainacc: 50.0 testacc: 50.0\n",
      "Epoch: 0058 cost = 0.206676215 trainacc: 50.0 testacc: 50.0\n",
      "Epoch: 0059 cost = 0.208134681 trainacc: 50.0 testacc: 50.0\n",
      "Epoch: 0060 cost = 0.207431912 trainacc: 50.0 testacc: 50.0\n",
      "Epoch: 0061 cost = 0.207068071 trainacc: 50.0 testacc: 50.0\n",
      "Epoch: 0062 cost = 0.205417931 trainacc: 50.0 testacc: 50.0\n",
      "Epoch: 0063 cost = 0.208490759 trainacc: 50.0 testacc: 50.0\n",
      "Epoch: 0064 cost = 0.209876865 trainacc: 50.0 testacc: 50.0\n",
      "Epoch: 0065 cost = 0.212796360 trainacc: 50.0 testacc: 50.0\n",
      "Epoch: 0066 cost = 0.206619680 trainacc: 50.0 testacc: 50.0\n",
      "Epoch: 0067 cost = 0.204968184 trainacc: 50.0 testacc: 50.0\n",
      "Epoch: 0068 cost = 0.209577486 trainacc: 50.0 testacc: 50.0\n",
      "Epoch: 0069 cost = 0.206726357 trainacc: 50.0 testacc: 50.0\n",
      "Epoch: 0070 cost = 0.205856770 trainacc: 50.0 testacc: 50.0\n",
      "Epoch: 0071 cost = 0.206163466 trainacc: 50.0 testacc: 50.0\n",
      "Epoch: 0072 cost = 0.208594158 trainacc: 50.0 testacc: 50.0\n",
      "Epoch: 0073 cost = 0.206299186 trainacc: 50.0 testacc: 50.0\n",
      "Epoch: 0074 cost = 0.204837918 trainacc: 50.0 testacc: 50.0\n",
      "Epoch: 0075 cost = 0.207839638 trainacc: 50.0 testacc: 50.0\n",
      "Epoch: 0076 cost = 0.209297881 trainacc: 50.0 testacc: 50.0\n",
      "Epoch: 0077 cost = 0.206467301 trainacc: 50.0 testacc: 50.0\n",
      "Epoch: 0078 cost = 0.205042988 trainacc: 50.0 testacc: 50.0\n",
      "Epoch: 0079 cost = 0.206191033 trainacc: 50.0 testacc: 50.0\n",
      "Epoch: 0080 cost = 0.205749154 trainacc: 50.0 testacc: 50.0\n",
      "Epoch: 0081 cost = 0.205801398 trainacc: 50.0 testacc: 50.0\n",
      "Epoch: 0082 cost = 0.205248266 trainacc: 50.0 testacc: 50.0\n",
      "Epoch: 0083 cost = 0.205816716 trainacc: 50.0 testacc: 50.0\n",
      "Epoch: 0084 cost = 0.206531748 trainacc: 50.0 testacc: 50.0\n",
      "Epoch: 0085 cost = 0.205145091 trainacc: 50.0 testacc: 50.0\n",
      "Epoch: 0086 cost = 0.206524238 trainacc: 50.0 testacc: 50.0\n",
      "Epoch: 0087 cost = 0.206326008 trainacc: 50.0 testacc: 50.0\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_11316\\203112485.py\u001b[0m in \u001b[0;36m<cell line: 3>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     55\u001b[0m             \u001b[0mdistance\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtargets\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfloat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     56\u001b[0m             \u001b[0mtargets\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtargets\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 57\u001b[1;33m             \u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtargets\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfloat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtargets\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mint64\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     58\u001b[0m             \u001b[0moutputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     59\u001b[0m             \u001b[0mloss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtargets\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdistance\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "total_batch = len(data_loader_train)\n",
    "\n",
    "for epoch in range(training_epochs):\n",
    "    model.train()\n",
    "    avg_cost = 0\n",
    "\n",
    "    # for X, Y in data_loader_train:\n",
    "    #     X = torch.autograd.Variable(X).to(device).float()\n",
    "    #     Y = Y.to(device)\n",
    "\n",
    "    #     optimizer.zero_grad()\n",
    "    #     hypothesis = model(X)\n",
    "    #     cost = criterion(hypothesis, Y)\n",
    "    #     cost.backward()\n",
    "    #     optimizer.step()\n",
    "\n",
    "    #     avg_cost += cost / total_batch\n",
    "    # model.train()\n",
    "    train_loss = 0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    for batch_idx, (inputs, targets) in enumerate(data_loader_train):\n",
    "        distance = targets[:,1].to(device).float()\n",
    "        targets = targets[:,0]\n",
    "        inputs, targets = inputs.to(device).float(), targets.to(device).to(torch.int64)\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, targets, distance)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        train_loss += loss.item()\n",
    "        _, predicted = outputs.max(1)\n",
    "        total += targets.size(0)\n",
    "        correct += predicted.eq(targets).sum().item()\n",
    "        avg_cost += loss / total_batch\n",
    "\n",
    "    \n",
    "    # if avg_cost < 0.1:\n",
    "    #     break\n",
    "    model.eval()\n",
    "    # with torch.no_grad():\n",
    "    #     for X_test, Y_test in data_loader_test:\n",
    "    #         X_test = X_test.to(device).float()\n",
    "    #         Y_test = Y_test.to(device)\n",
    "\n",
    "    #     prediction = model(X_test)\n",
    "    #     correct_prediction = torch.argmax(prediction, 1) == Y_test\n",
    "    #     accuracy = correct_prediction.float().mean()\n",
    "    test_loss = 0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for batch_idx, (inputs, targets) in enumerate(data_loader_train):\n",
    "            distance = targets[:,1].to(device).float()\n",
    "            targets = targets[:,0]\n",
    "            inputs, targets = inputs.to(device).float(), targets.to(device).to(torch.int64)\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, targets, distance)\n",
    "\n",
    "            test_loss += loss.item()\n",
    "            _, predicted = outputs.max(1)\n",
    "            total += targets.size(0)\n",
    "            correct += predicted.eq(targets).sum().item()\n",
    "    trainacc = 100.*correct/total\n",
    "    test_loss = 0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for batch_idx, (inputs, targets) in enumerate(data_loader_test):\n",
    "            distance = targets[:,1].to(device).float()\n",
    "            targets = targets[:,0]\n",
    "            inputs, targets = inputs.to(device).float(), targets.to(device).to(torch.int64)\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, targets, distance)\n",
    "\n",
    "            test_loss += loss.item()\n",
    "            _, predicted = outputs.max(1)\n",
    "            total += targets.size(0)\n",
    "            correct += predicted.eq(targets).sum().item()\n",
    "    testacc = 100.*correct/total\n",
    "    print('Epoch:', '%04d' % (epoch + 1), 'cost =', '{:.9f}'.format(avg_cost), 'trainacc:', trainacc, 'testacc:', testacc)\n",
    "\n",
    "print('Learning finished')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "# Test the model using test sets\n",
    "# model.load_state_dict(torch.load(\".\\merge_save\\merge_attack0normal10_05-07--21-10-32.pth\")[\"state_dict\"])\n",
    "# model.load_state_dict(torch.load(r\".\\myfed_normal_save\\model18-24-02.pth\")[\"state_dict\"])\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    for X_test, Y_test in data_loader_test:\n",
    "        X_test = X_test.to(device).float()\n",
    "        Y_test = Y_test.to(device)\n",
    "\n",
    "        prediction = model(X_test)\n",
    "        correct_prediction = torch.argmax(prediction, 1) == Y_test\n",
    "        print(prediction,correct_prediction, Y_test)\n",
    "        accuracy = correct_prediction.float().mean()\n",
    "        print('Accuracy:', accuracy.item())\n",
    "\n",
    "    # Get one and predict\n",
    "    # r = random.randint(0, len(mnist_test) - 1)\n",
    "    # X_single_data = mnist_test.data[r:r + 1].view(-1, 28 * 28).float().to(device)\n",
    "    # Y_single_data = mnist_test.targets[r:r + 1].to(device)\n",
    "\n",
    "    # print('Label: ', Y_single_data.item())\n",
    "    # single_prediction = model(X_single_data)\n",
    "    # print('Prediction: ', torch.argmax(single_prediction, 1).item())\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "vscode": {
   "interpreter": {
    "hash": "1d28dcb1746f058774bc7e3103f8fd674f9a46f28636659ba6a6fdaf0b17e1a8"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
