{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "load the classifier and evaluate it on the test set\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "from itertools import product\n",
    "\n",
    "import time\n",
    "import numpy as np\n",
    "from sklearn import datasets\n",
    "from scipy.stats import multivariate_normal as mvn\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from ripser import Rips\n",
    "from persim import PersistenceImager\n",
    "\n",
    "import os\n",
    "import math\n",
    "\n",
    "import seaborn\n",
    "import pandas as pd\n",
    "import torch\n",
    "import random\n",
    "from torch import nn\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "import re\n",
    "import cv2\n",
    "from PIL import Image\n",
    "\n",
    "import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "# for reproducibility\n",
    "random.seed(111)\n",
    "torch.manual_seed(777)\n",
    "if device == 'cuda':\n",
    "    torch.cuda.manual_seed_all(777)\n",
    "# parameters\n",
    "learning_rate = 0.001\n",
    "training_epochs = 600\n",
    "batchsize = 32\n",
    "testbatchsize = 16\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "# dir = os.listdir(\"./metric\")\n",
    "# data = []\n",
    "# a = []\n",
    "# for metric in dir:\n",
    "#     a = re.findall(\"\\d+\\.?\\d*\", metric)\n",
    "#     data.append([np.loadtxt(\"./metric/\"+metric), metric])\n",
    "#     # print(a[-2])\n",
    "#     print(metric[-2])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "class My_dataset(Dataset):\n",
    "    def __init__(self, train):\n",
    "        super().__init__()\n",
    "        # 使用sin函数返回10000个时间序列,如果不自己构造数据，就使用numpy,pandas等读取自己的数据为x即可。\n",
    "        # 以下数据组织这块既可以放在init方法里，也可以放在getitem方法里\n",
    "        dir = os.listdir(\"./grids_single_trainset\")\n",
    "        dirtest = os.listdir(\"./grids_eval\")\n",
    "        data = []\n",
    "        a = []\n",
    "        if train:\n",
    "            # for metric in dir:\n",
    "            #     data.append(\n",
    "            #         [np.loadtxt(\"./grids_trainset_cifar/\"+metric), metric])\n",
    "            sample = []\n",
    "            for metric in dir:\n",
    "                sample.append([np.loadtxt(\"./grids_single_trainset/\"+metric), metric])\n",
    "                if len(sample) == 4:\n",
    "                    res = cv2.merge([i[0] for i in sample])\n",
    "                    res = np.transpose(res,(2,0,1))\n",
    "                    data.append([res, metric])\n",
    "                    sample = []\n",
    "            \n",
    "        else:\n",
    "            # for metric in dirtest:\n",
    "            #     data.append(\n",
    "            #         [np.loadtxt(\"./grids_testset_cifar/\"+metric), metric])\n",
    "            sample = []\n",
    "            for metric in dirtest:\n",
    "                sample.append([np.loadtxt(\"./grids_eval/\"+metric), metric])\n",
    "                if len(sample) == 4:\n",
    "                    res = cv2.merge([i[0] for i in sample])\n",
    "                    res = np.transpose(res,(2,0,1))\n",
    "                    data.append([res, metric])\n",
    "                    sample = []\n",
    "\n",
    "        self.x = [item[0] for item in data]\n",
    "        self.y = [int(item[1][0:len(\"h_vr_metric-single-leNet_morefc-continue=mnist_moreFC_global-2_attack_8\")] == \"h_vr_metric-single-leNet_morefc-continue=mnist_moreFC_global-2_attack_8\") for item in data]\n",
    "        # self.y = [int(re.findall(\"\\d+\\.?\\d*\", item[1])[0]) for item in data]\n",
    "        self.src,  self.trg = [], []\n",
    "        for i in range(len(data)):\n",
    "            self.src.append(self.x[i])\n",
    "            self.trg.append(self.y[i])\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        return self.src[index], self.trg[index]\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.src)\n",
    "\n",
    " # 或者return len(self.trg), src和trg长度一样\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test\n",
      "0\n",
      "torch.Size([12, 4, 128, 128])\n",
      "tensor([0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1])\n"
     ]
    }
   ],
   "source": [
    "data_tf = transforms.Compose(\n",
    "    [transforms.ToTensor(),\n",
    "     transforms.Normalize([0.5], [0.5])])\n",
    "     \n",
    "data_test = My_dataset(train=False)\n",
    "data_loader_test = DataLoader(data_test, batch_size=testbatchsize, shuffle=False)\n",
    "\n",
    "\n",
    "print(\"test\")\n",
    "for i_batch, batch_data in enumerate(data_loader_test):\n",
    "    print(i_batch)  # 打印batch编号\n",
    "    print(batch_data[0].shape)  # 打印该batch里面src\n",
    "    print(batch_data[1])  # 打印该batch里面trg\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class MyNet(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(MyNet, self).__init__()\n",
    "        self.layer1 = torch.nn.Sequential(\n",
    "            torch.nn.Conv2d(4, 16, kernel_size=64),\n",
    "            torch.nn.BatchNorm2d(16),\n",
    "            torch.nn.ReLU(inplace=True)\n",
    "        )\n",
    "\n",
    "        self.layer2 = torch.nn.Sequential(\n",
    "            torch.nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        )\n",
    "\n",
    "        self.fc = torch.nn.Sequential(\n",
    "            torch.nn.Linear(16 * 32 * 32, 1024),\n",
    "            torch.nn.ReLU(inplace=True),\n",
    "            torch.nn.Linear(1024, 1024),\n",
    "            torch.nn.ReLU(inplace=True),\n",
    "            torch.nn.Linear(1024, 128),\n",
    "            torch.nn.ReLU(inplace=True),\n",
    "            torch.nn.Linear(128, 64),\n",
    "            torch.nn.ReLU(inplace=True),\n",
    "            torch.nn.Linear(64, 2)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.layer1(x)\n",
    "        x = self.layer2(x)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = self.fc(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "model = MyNet().to(device)\n",
    "model.load_state_dict(torch.load('./classifier/single=07-18--21-27-13.pth')[\"state_dict\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "# define cost/loss & optimizer\n",
    "# Softmax is internally computed.\n",
    "criterion = torch.nn.CrossEntropyLoss().to(device)\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 3.9552, -3.9408],\n",
      "        [ 0.1528, -0.2748],\n",
      "        [ 4.3995, -4.5735],\n",
      "        [-2.9087,  2.4308],\n",
      "        [ 1.0717, -1.3018],\n",
      "        [ 0.0122, -0.0246],\n",
      "        [ 0.1151, -0.2514],\n",
      "        [-0.4324,  0.1780],\n",
      "        [ 0.3071, -0.4691],\n",
      "        [ 0.0660, -0.3785],\n",
      "        [ 1.0297, -1.2225],\n",
      "        [-0.7202,  0.3263]], device='cuda:0') tensor([ True,  True,  True, False,  True,  True,  True,  True, False, False,\n",
      "        False,  True], device='cuda:0') tensor([0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1], device='cuda:0')\n",
      "Accuracy: 0.6666666865348816\n"
     ]
    }
   ],
   "source": [
    "# Test the model using test sets\n",
    "# model.load_state_dict(torch.load(\".\\merge_save\\merge_attack0normal10_05-07--21-10-32.pth\")[\"state_dict\"])\n",
    "# model.load_state_dict(torch.load(r\".\\myfed_normal_save\\model18-24-02.pth\")[\"state_dict\"])\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    for X_test, Y_test in data_loader_test:\n",
    "        X_test = X_test.to(device).float()\n",
    "        Y_test = Y_test.to(device)\n",
    "\n",
    "        prediction = model(X_test)\n",
    "        correct_prediction = torch.argmax(prediction, 1) == Y_test\n",
    "        print(prediction,correct_prediction, Y_test)\n",
    "        accuracy = correct_prediction.float().mean()\n",
    "        print('Accuracy:', accuracy.item())\n",
    "\n",
    "    # Get one and predict\n",
    "    # r = random.randint(0, len(mnist_test) - 1)\n",
    "    # X_single_data = mnist_test.data[r:r + 1].view(-1, 28 * 28).float().to(device)\n",
    "    # Y_single_data = mnist_test.targets[r:r + 1].to(device)\n",
    "\n",
    "    # print('Label: ', Y_single_data.item())\n",
    "    # single_prediction = model(X_single_data)\n",
    "    # print('Prediction: ', torch.argmax(single_prediction, 1).item())\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "vscode": {
   "interpreter": {
    "hash": "1d28dcb1746f058774bc7e3103f8fd674f9a46f28636659ba6a6fdaf0b17e1a8"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
