{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lab 10 MNIST and softmax\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import torch.optim as optim\n",
    "import torch.backends.cudnn as cudnn\n",
    "import time\n",
    "import random\n",
    "import datetime\n",
    "import os\n",
    "import sys\n",
    "\n",
    "import numpy as np\n",
    "import copy\n",
    "\n",
    "# torch.set_printoptions(profile=\"full\")\n",
    "# np.set_printoptions(threshold=np.inf)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "# for reproducibility\n",
    "random.seed(111)\n",
    "torch.manual_seed(777)\n",
    "if device == 'cuda':\n",
    "    torch.cuda.manual_seed_all(777)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# parameters\n",
    "learning_rate = 0.001\n",
    "training_epochs = 5\n",
    "batch_size = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.Compose(\n",
    "    [\n",
    "     transforms.RandomHorizontalFlip(),\n",
    "     transforms.RandomGrayscale(),\n",
    "     transforms.ToTensor(),\n",
    "     transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
    "\n",
    "transform1 = transforms.Compose(\n",
    "    [\n",
    "     transforms.ToTensor(),\n",
    "     transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
    "     \n",
    "transform_test = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "trainset = torchvision.datasets.CIFAR10(root='CIFAR10_data/', train=True,\n",
    "                                        download=True, transform=transform)\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=100,\n",
    "                                          shuffle=True, num_workers=2)\n",
    "\n",
    "testset = torchvision.datasets.CIFAR10(root='CIFAR10_data/', train=False,\n",
    "                                       download=True, transform=transform1)\n",
    "testloader = torch.utils.data.DataLoader(testset, batch_size=50,\n",
    "                                         shuffle=False, num_workers=2)\n",
    "\n",
    "classes = ('plane', 'car', 'bird', 'cat',\n",
    "           'deer', 'dog', 'frog', 'horse', 'ship', 'truck')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataParallel(\n",
      "  (module): Net(\n",
      "    (conv1): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (pool1): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu1): ReLU()\n",
      "    (conv3): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (conv4): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (pool2): MaxPool2d(kernel_size=2, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
      "    (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu2): ReLU()\n",
      "    (conv5): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (conv6): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (conv7): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), padding=(1, 1))\n",
      "    (pool3): MaxPool2d(kernel_size=2, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
      "    (bn3): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu3): ReLU()\n",
      "    (conv8): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (conv9): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (conv10): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1), padding=(1, 1))\n",
      "    (pool4): MaxPool2d(kernel_size=2, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
      "    (bn4): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu4): ReLU()\n",
      "    (conv11): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (conv12): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (conv13): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1), padding=(1, 1))\n",
      "    (pool5): MaxPool2d(kernel_size=2, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
      "    (bn5): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu5): ReLU()\n",
      "    (fc14): Linear(in_features=8192, out_features=1024, bias=True)\n",
      "    (drop1): Dropout2d(p=0.5, inplace=False)\n",
      "    (fc15): Linear(in_features=1024, out_features=128, bias=True)\n",
      "    (drop2): Dropout2d(p=0.5, inplace=False)\n",
      "    (fc16): Linear(in_features=128, out_features=10, bias=True)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "class Net(nn.Module):\n",
    "\n",
    "    def __init__(self):\n",
    "        super(Net,self).__init__()\n",
    "        self.conv1 = nn.Conv2d(3,64,3,padding=1)\n",
    "        self.conv2 = nn.Conv2d(64,64,3,padding=1)\n",
    "        self.pool1 = nn.MaxPool2d(2, 2)\n",
    "        self.bn1 = nn.BatchNorm2d(64)\n",
    "        self.relu1 = nn.ReLU()\n",
    "\n",
    "        self.conv3 = nn.Conv2d(64,128,3,padding=1)\n",
    "        self.conv4 = nn.Conv2d(128, 128, 3,padding=1)\n",
    "        self.pool2 = nn.MaxPool2d(2, 2, padding=1)\n",
    "        self.bn2 = nn.BatchNorm2d(128)\n",
    "        self.relu2 = nn.ReLU()\n",
    "\n",
    "        self.conv5 = nn.Conv2d(128,128, 3,padding=1)\n",
    "        self.conv6 = nn.Conv2d(128, 128, 3,padding=1)\n",
    "        self.conv7 = nn.Conv2d(128, 128, 1,padding=1)\n",
    "        self.pool3 = nn.MaxPool2d(2, 2, padding=1)\n",
    "        self.bn3 = nn.BatchNorm2d(128)\n",
    "        self.relu3 = nn.ReLU()\n",
    "\n",
    "        self.conv8 = nn.Conv2d(128, 256, 3,padding=1)\n",
    "        self.conv9 = nn.Conv2d(256, 256, 3, padding=1)\n",
    "        self.conv10 = nn.Conv2d(256, 256, 1, padding=1)\n",
    "        self.pool4 = nn.MaxPool2d(2, 2, padding=1)\n",
    "        self.bn4 = nn.BatchNorm2d(256)\n",
    "        self.relu4 = nn.ReLU()\n",
    "\n",
    "        self.conv11 = nn.Conv2d(256, 512, 3, padding=1)\n",
    "        self.conv12 = nn.Conv2d(512, 512, 3, padding=1)\n",
    "        self.conv13 = nn.Conv2d(512, 512, 1, padding=1)\n",
    "        self.pool5 = nn.MaxPool2d(2, 2, padding=1)\n",
    "        self.bn5 = nn.BatchNorm2d(512)\n",
    "        self.relu5 = nn.ReLU()\n",
    "\n",
    "        self.fc14 = nn.Linear(512*4*4,1024)\n",
    "        self.drop1 = nn.Dropout2d()\n",
    "        self.fc15 = nn.Linear(1024,128)\n",
    "        self.drop2 = nn.Dropout2d()\n",
    "        self.fc16 = nn.Linear(128,10)\n",
    "\n",
    "\n",
    "    def forward(self,x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.conv2(x)\n",
    "        x = self.pool1(x)\n",
    "        x = self.bn1(x)\n",
    "        x = self.relu1(x)\n",
    "\n",
    "\n",
    "        x = self.conv3(x)\n",
    "        x = self.conv4(x)\n",
    "        x = self.pool2(x)\n",
    "        x = self.bn2(x)\n",
    "        x = self.relu2(x)\n",
    "\n",
    "        x = self.conv5(x)\n",
    "        x = self.conv6(x)\n",
    "        x = self.conv7(x)\n",
    "        x = self.pool3(x)\n",
    "        x = self.bn3(x)\n",
    "        x = self.relu3(x)\n",
    "\n",
    "        x = self.conv8(x)\n",
    "        x = self.conv9(x)\n",
    "        x = self.conv10(x)\n",
    "        x = self.pool4(x)\n",
    "        x = self.bn4(x)\n",
    "        x = self.relu4(x)\n",
    "\n",
    "        x = self.conv11(x)\n",
    "        x = self.conv12(x)\n",
    "        x = self.conv13(x)\n",
    "        x = self.pool5(x)\n",
    "        x = self.bn5(x)\n",
    "        x = self.relu5(x)\n",
    "        # print(\" x shape \",x.size())\n",
    "        x = x.view(-1,512*4*4)\n",
    "        x = F.relu(self.fc14(x))\n",
    "        x = self.drop1(x)\n",
    "        x = F.relu(self.fc15(x))\n",
    "        x = self.drop2(x)\n",
    "        x = self.fc16(x)\n",
    "\n",
    "        return x\n",
    "\n",
    "model = Net().to(device)\n",
    "if device == 'cuda':\n",
    "    model = torch.nn.DataParallel(model)\n",
    "    cudnn.benchmark = True\n",
    "\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.01,\n",
    "                      momentum=0.9, weight_decay=5e-4)\n",
    "scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=200)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# total_batch = len(data_loader)\n",
    "# model.train()\n",
    "# for epoch in range(training_epochs):\n",
    "#     avg_cost = 0\n",
    "\n",
    "#     for X, Y in data_loader:\n",
    "#         X = torch.autograd.Variable(X).to(device)\n",
    "#         Y = Y.to(device)\n",
    "\n",
    "#         optimizer.zero_grad()\n",
    "#         hypothesis = model(X)\n",
    "#         cost = criterion(hypothesis, Y)\n",
    "#         cost.backward()\n",
    "#         optimizer.step()\n",
    "\n",
    "#         avg_cost += cost / total_batch\n",
    "\n",
    "#     print('Epoch:', '%04d' % (epoch + 1), 'cost =', '{:.9f}'.format(avg_cost))\n",
    "\n",
    "# print('Learning finished')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # model.load_state_dict(torch.load(\"./myfed_normal_save/model18-32-05.pth\")[\"state_dict\"])\n",
    "# dir = os.listdir(\"./saved_models\")\n",
    "# models = []\n",
    "# for mt in dir:\n",
    "#     if mt[0:len(\"cifar_test\")] == \"cifar_test\" and mt[0:len(\"cifar_test_\")] != \"cifar_test_\":\n",
    "#         models.append(mt)\n",
    "# modelname = models[-1]\n",
    "# model.load_state_dict(torch.load(\"./saved_models/\"+modelname)[\"state_dict\"])\n",
    "# print(modelname)\n",
    "# savepath = \"./metric/vr_metric_single_convFeature=\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['merge_cifartest_attack0normal15_06-05--21-30-03.pth', 'merge_cifartest_attack0normal15_06-05--22-12-15.pth', 'merge_cifartest_attack0normal15_06-05--22-12-21.pth', 'merge_cifartest_attack0normal15_06-05--22-12-25.pth', 'merge_cifartest_attack0normal15_06-05--22-13-02.pth', 'merge_cifartest_attack0normal15_06-05--22-13-11.pth', 'merge_cifartest_attack0normal15_06-05--22-13-29.pth', 'merge_cifartest_attack0normal15_06-05--22-13-32.pth', 'merge_cifartest_attack0normal15_06-05--22-13-50.pth', 'merge_cifartest_attack0normal15_06-05--22-13-54.pth', 'merge_cifartest_attack0normal15_06-05--22-13-58.pth', 'merge_cifartest_attack0normal15_06-05--22-14-02.pth', 'merge_cifartest_attack0normal15_06-05--22-14-07.pth', 'merge_cifartest_attack0normal15_06-05--22-14-10.pth', 'merge_cifartest_attack0normal15_06-05--22-14-14.pth', 'merge_cifartest_attack0normal15_06-05--22-14-18.pth', 'merge_cifartest_attack0normal15_06-05--22-14-42.pth', 'merge_cifartest_attack0normal15_06-05--22-14-45.pth', 'merge_cifartest_attack0normal15_06-05--22-14-49.pth', 'merge_cifartest_attack0normal15_06-05--22-14-52.pth', 'merge_cifartest_attack0normal15_06-05--22-14-55.pth', 'merge_cifartest_attack0normal15_06-05--22-14-58.pth', 'merge_cifartest_attack0normal15_06-05--22-15-02.pth', 'merge_cifartest_attack1normal14_06-05--21-23-14.pth', 'merge_cifartest_attack1normal14_06-05--21-25-10.pth', 'merge_cifartest_attack1normal14_06-05--21-25-36.pth', 'merge_cifartest_attack1normal14_06-05--21-26-28.pth', 'merge_cifartest_attack1normal14_06-05--21-26-32.pth', 'merge_cifartest_attack1normal14_06-05--21-26-41.pth', 'merge_cifartest_attack1normal14_06-05--21-27-54.pth', 'merge_cifartest_attack2normal13_06-05--21-22-55.pth', 'merge_cifartest_attack2normal13_06-05--21-23-05.pth', 'merge_cifartest_attack2normal13_06-05--21-23-18.pth', 'merge_cifartest_attack2normal13_06-05--21-24-34.pth', 'merge_cifartest_attack2normal13_06-05--21-25-07.pth', 'merge_cifartest_attack2normal13_06-05--21-25-16.pth', 'merge_cifartest_attack2normal13_06-05--21-25-40.pth', 'merge_cifartest_attack2normal13_06-05--21-26-20.pth', 'merge_cifartest_attack2normal13_06-05--21-26-37.pth', 'merge_cifartest_attack2normal13_06-05--21-27-51.pth', 'merge_cifartest_attack2normal13_06-05--21-28-02.pth', 'merge_cifartest_attack2normal13_06-05--21-28-22.pth', 'merge_cifartest_attack2normal13_06-05--21-29-59.pth', 'merge_cifartest_attack2normal13_06-05--21-30-13.pth', 'merge_cifartest_attack3normal12_06-05--21-23-22.pth', 'merge_cifartest_attack3normal12_06-05--21-23-30.pth', 'merge_cifartest_attack3normal12_06-05--21-25-02.pth', 'merge_cifartest_attack3normal12_06-05--21-25-20.pth', 'merge_cifartest_attack3normal12_06-05--21-25-24.pth', 'merge_cifartest_attack3normal12_06-05--21-25-32.pth', 'merge_cifartest_attack3normal12_06-05--21-26-17.pth', 'merge_cifartest_attack3normal12_06-05--21-27-40.pth', 'merge_cifartest_attack3normal12_06-05--21-28-09.pth', 'merge_cifartest_attack3normal12_06-05--21-28-26.pth', 'merge_cifartest_attack3normal12_06-05--21-29-55.pth', 'merge_cifartest_attack3normal12_06-05--21-30-09.pth']\n"
     ]
    }
   ],
   "source": [
    "# model.load_state_dict(torch.load(\"./myfed_normal_save/model18-32-05.pth\")[\"state_dict\"])\n",
    "dir = os.listdir(\"./merge_save\")\n",
    "modelnames = []\n",
    "for mt in dir:\n",
    "    if(mt[0:len(\"merge_cifartest\")] == \"merge_cifartest\"):\n",
    "        modelnames.append(mt)\n",
    "print(modelnames)\n",
    "modelset = []\n",
    "for mn in modelnames:\n",
    "    modelset.append([model.load_state_dict(torch.load(\"./merge_save/\"+mn)[\"state_dict\"]),mn])\n",
    "# print(dir)\n",
    "savepath = \"./metric/vr_metric_convFeature_0-10=\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./metric/vr_metric_convFeature_0-10=merge_cifartest_attack0normal15_06-05--21-30-03.pth06-16--18-57-22.dat\n",
      "./metric/vr_metric_convFeature_0-10=merge_cifartest_attack0normal15_06-05--22-12-15.pth06-16--18-57-41.dat\n",
      "./metric/vr_metric_convFeature_0-10=merge_cifartest_attack0normal15_06-05--22-12-21.pth06-16--18-58-04.dat\n",
      "./metric/vr_metric_convFeature_0-10=merge_cifartest_attack0normal15_06-05--22-12-25.pth06-16--18-58-41.dat\n",
      "./metric/vr_metric_convFeature_0-10=merge_cifartest_attack0normal15_06-05--22-13-02.pth06-16--18-59-00.dat\n",
      "./metric/vr_metric_convFeature_0-10=merge_cifartest_attack0normal15_06-05--22-13-11.pth06-16--18-59-38.dat\n",
      "./metric/vr_metric_convFeature_0-10=merge_cifartest_attack0normal15_06-05--22-13-29.pth06-16--19-00-01.dat\n",
      "./metric/vr_metric_convFeature_0-10=merge_cifartest_attack0normal15_06-05--22-13-32.pth06-16--19-00-23.dat\n",
      "./metric/vr_metric_convFeature_0-10=merge_cifartest_attack0normal15_06-05--22-13-50.pth06-16--19-00-42.dat\n",
      "./metric/vr_metric_convFeature_0-10=merge_cifartest_attack0normal15_06-05--22-13-54.pth06-16--19-01-00.dat\n",
      "./metric/vr_metric_convFeature_0-10=merge_cifartest_attack0normal15_06-05--22-13-58.pth06-16--19-01-19.dat\n",
      "./metric/vr_metric_convFeature_0-10=merge_cifartest_attack0normal15_06-05--22-14-02.pth06-16--19-01-47.dat\n",
      "./metric/vr_metric_convFeature_0-10=merge_cifartest_attack0normal15_06-05--22-14-07.pth06-16--19-02-05.dat\n",
      "./metric/vr_metric_convFeature_0-10=merge_cifartest_attack0normal15_06-05--22-14-10.pth06-16--19-02-24.dat\n",
      "./metric/vr_metric_convFeature_0-10=merge_cifartest_attack0normal15_06-05--22-14-14.pth06-16--19-02-43.dat\n",
      "./metric/vr_metric_convFeature_0-10=merge_cifartest_attack0normal15_06-05--22-14-18.pth06-16--19-03-16.dat\n",
      "./metric/vr_metric_convFeature_0-10=merge_cifartest_attack0normal15_06-05--22-14-42.pth06-16--19-03-40.dat\n",
      "./metric/vr_metric_convFeature_0-10=merge_cifartest_attack0normal15_06-05--22-14-45.pth06-16--19-03-59.dat\n",
      "./metric/vr_metric_convFeature_0-10=merge_cifartest_attack0normal15_06-05--22-14-49.pth06-16--19-04-18.dat\n",
      "./metric/vr_metric_convFeature_0-10=merge_cifartest_attack0normal15_06-05--22-14-52.pth06-16--19-04-41.dat\n",
      "./metric/vr_metric_convFeature_0-10=merge_cifartest_attack0normal15_06-05--22-14-55.pth06-16--19-05-00.dat\n",
      "./metric/vr_metric_convFeature_0-10=merge_cifartest_attack0normal15_06-05--22-14-58.pth06-16--19-05-28.dat\n",
      "./metric/vr_metric_convFeature_0-10=merge_cifartest_attack0normal15_06-05--22-15-02.pth06-16--19-05-46.dat\n",
      "./metric/vr_metric_convFeature_0-10=merge_cifartest_attack1normal14_06-05--21-23-14.pth06-16--19-06-05.dat\n",
      "./metric/vr_metric_convFeature_0-10=merge_cifartest_attack1normal14_06-05--21-25-10.pth06-16--19-06-30.dat\n",
      "./metric/vr_metric_convFeature_0-10=merge_cifartest_attack1normal14_06-05--21-25-36.pth06-16--19-06-49.dat\n",
      "./metric/vr_metric_convFeature_0-10=merge_cifartest_attack1normal14_06-05--21-26-28.pth06-16--19-07-08.dat\n",
      "./metric/vr_metric_convFeature_0-10=merge_cifartest_attack1normal14_06-05--21-26-32.pth06-16--19-07-32.dat\n",
      "./metric/vr_metric_convFeature_0-10=merge_cifartest_attack1normal14_06-05--21-26-41.pth06-16--19-07-51.dat\n",
      "./metric/vr_metric_convFeature_0-10=merge_cifartest_attack1normal14_06-05--21-27-54.pth06-16--19-08-10.dat\n",
      "./metric/vr_metric_convFeature_0-10=merge_cifartest_attack2normal13_06-05--21-22-55.pth06-16--19-08-29.dat\n",
      "./metric/vr_metric_convFeature_0-10=merge_cifartest_attack2normal13_06-05--21-23-05.pth06-16--19-08-47.dat\n",
      "./metric/vr_metric_convFeature_0-10=merge_cifartest_attack2normal13_06-05--21-23-18.pth06-16--19-09-06.dat\n",
      "./metric/vr_metric_convFeature_0-10=merge_cifartest_attack2normal13_06-05--21-24-34.pth06-16--19-09-34.dat\n",
      "./metric/vr_metric_convFeature_0-10=merge_cifartest_attack2normal13_06-05--21-25-07.pth06-16--19-09-53.dat\n",
      "./metric/vr_metric_convFeature_0-10=merge_cifartest_attack2normal13_06-05--21-25-16.pth06-16--19-10-12.dat\n",
      "./metric/vr_metric_convFeature_0-10=merge_cifartest_attack2normal13_06-05--21-25-40.pth06-16--19-10-30.dat\n",
      "./metric/vr_metric_convFeature_0-10=merge_cifartest_attack2normal13_06-05--21-26-20.pth06-16--19-10-49.dat\n",
      "./metric/vr_metric_convFeature_0-10=merge_cifartest_attack2normal13_06-05--21-26-37.pth06-16--19-11-08.dat\n",
      "./metric/vr_metric_convFeature_0-10=merge_cifartest_attack2normal13_06-05--21-27-51.pth06-16--19-11-31.dat\n",
      "./metric/vr_metric_convFeature_0-10=merge_cifartest_attack2normal13_06-05--21-28-02.pth06-16--19-11-50.dat\n",
      "./metric/vr_metric_convFeature_0-10=merge_cifartest_attack2normal13_06-05--21-28-22.pth06-16--19-12-08.dat\n",
      "./metric/vr_metric_convFeature_0-10=merge_cifartest_attack2normal13_06-05--21-29-59.pth06-16--19-12-27.dat\n",
      "./metric/vr_metric_convFeature_0-10=merge_cifartest_attack2normal13_06-05--21-30-13.pth06-16--19-12-46.dat\n",
      "./metric/vr_metric_convFeature_0-10=merge_cifartest_attack3normal12_06-05--21-23-22.pth06-16--19-13-05.dat\n",
      "./metric/vr_metric_convFeature_0-10=merge_cifartest_attack3normal12_06-05--21-23-30.pth06-16--19-13-24.dat\n",
      "./metric/vr_metric_convFeature_0-10=merge_cifartest_attack3normal12_06-05--21-25-02.pth06-16--19-13-42.dat\n",
      "./metric/vr_metric_convFeature_0-10=merge_cifartest_attack3normal12_06-05--21-25-20.pth06-16--19-14-01.dat\n",
      "./metric/vr_metric_convFeature_0-10=merge_cifartest_attack3normal12_06-05--21-25-24.pth06-16--19-14-20.dat\n",
      "./metric/vr_metric_convFeature_0-10=merge_cifartest_attack3normal12_06-05--21-25-32.pth06-16--19-14-49.dat\n",
      "./metric/vr_metric_convFeature_0-10=merge_cifartest_attack3normal12_06-05--21-26-17.pth06-16--19-15-08.dat\n",
      "./metric/vr_metric_convFeature_0-10=merge_cifartest_attack3normal12_06-05--21-27-40.pth06-16--19-15-27.dat\n",
      "./metric/vr_metric_convFeature_0-10=merge_cifartest_attack3normal12_06-05--21-28-09.pth06-16--19-15-46.dat\n",
      "./metric/vr_metric_convFeature_0-10=merge_cifartest_attack3normal12_06-05--21-28-26.pth06-16--19-16-04.dat\n",
      "./metric/vr_metric_convFeature_0-10=merge_cifartest_attack3normal12_06-05--21-29-55.pth06-16--19-16-37.dat\n",
      "./metric/vr_metric_convFeature_0-10=merge_cifartest_attack3normal12_06-05--21-30-09.pth06-16--19-17-00.dat\n"
     ]
    }
   ],
   "source": [
    "for mode, modelname in modelset:\n",
    "    parm = {}\n",
    "    for name,parameters in model.named_parameters():\n",
    "        parm[name]=parameters\n",
    "        # print(parm[name])\n",
    "    tensors = []\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "\n",
    "        t=10\n",
    "        for i in range(0,t):\n",
    "            r = random.randint(0, (batch_size) - 1)\n",
    "\n",
    "            for X_test, Y_test in testloader:\n",
    "                X_test = X_test.to(device)\n",
    "                Y_test = Y_test.to(device)\n",
    "            \n",
    "\n",
    "            X_single_data = X_test[r]\n",
    "            Y_single_data = Y_test[r]\n",
    "\n",
    "            # print(X_single_data)\n",
    "            \n",
    "            layerP = model.module.conv1(torch.unsqueeze(X_single_data,dim=0))\n",
    "            # print(\"1\",layerP)\n",
    "            layerP = model.module.conv2(layerP)\n",
    "            # print(\"2\",layerP)\n",
    "            layerP = model.module.pool1(layerP)\n",
    "            layerP = model.module.bn1(layerP)\n",
    "            layerP = model.module.relu1(layerP)\n",
    "            # print(\"3\",layerP)\n",
    "            layerP = model.module.conv3(layerP)\n",
    "            layerP = model.module.conv4(layerP)\n",
    "            layerP = model.module.pool2(layerP)\n",
    "            layerP = model.module.bn2(layerP)\n",
    "            layerP = model.module.relu2(layerP)\n",
    "            layerP = model.module.conv5(layerP)\n",
    "            layerP = model.module.conv6(layerP)\n",
    "            layerP = model.module.conv7(layerP)\n",
    "            layerP = model.module.pool3(layerP)\n",
    "            layerP = model.module.bn3(layerP)\n",
    "            layerP = model.module.relu3(layerP)\n",
    "            layerP = model.module.conv8(layerP)\n",
    "            layerP = model.module.conv9(layerP)\n",
    "            layerP = model.module.conv10(layerP)\n",
    "            layerP = model.module.pool4(layerP)\n",
    "            layerP = model.module.bn4(layerP)\n",
    "            layerP = model.module.relu4(layerP)\n",
    "            # layerP = model.module.conv11(layerP)\n",
    "            # layerP = model.module.conv12(layerP)\n",
    "            # layerP = model.module.conv13(layerP)\n",
    "            # layerP = model.module.pool5(layerP)\n",
    "            # layerP = model.module.bn5(layerP)\n",
    "            # layerP = model.module.relu5(layerP)\n",
    "            # layerP = layerP.detach().squeeze().reshape(-1,512*4*4)\n",
    "\n",
    "            # tensor1 = torch.mm(layerP, parm['module.fc14.weight'].data.permute(1,0)) + parm['module.fc14.bias']\n",
    "            # tensor1 = torch.mm(tensor1, parm['module.fc15.weight'].data.permute(1,0)) + parm['module.fc15.bias']\n",
    "            \n",
    "            # tensors.append(tensor1.cpu().detach().numpy()[0])\n",
    "\n",
    "            layerP = layerP.squeeze().reshape(-1,80)\n",
    "\n",
    "            # tensor1 = torch.mm(layerP, parm['module.fc14.weight'].data.permute(1,0)) + parm['module.fc14.bias']\n",
    "            # tensor1 = torch.mm(tensor1, parm['module.fc15.weight'].data.permute(1,0)) + parm['module.fc15.bias']\n",
    "            # print(layerP.shape)\n",
    "            tensors.append(layerP.cpu().detach().numpy()[0])\n",
    "\n",
    "    nb = np.linspace(0,0,tensors[0].shape[0])\n",
    "    for i in tensors:\n",
    "        nb += i\n",
    "    nb /= t\n",
    "\n",
    "    ns = np.linspace(0,0,tensors[0].shape[0])\n",
    "    vp = np.linspace(0,0,tensors[0].shape[0] ** 2).reshape(tensors[0].shape[0],tensors[0].shape[0])\n",
    "\n",
    "    for i in range(0,len(ns)):\n",
    "        for nps in tensors:\n",
    "            ns[i] += nps[i] ** 2\n",
    "        ns[i] = ns[i] ** 0.5\n",
    "\n",
    "    for i in range(0,len(ns)):\n",
    "        for j in range(i+1,len(ns)):\n",
    "            for nps in tensors:\n",
    "                vp[i,j] += (nps[i] - nb[i]) * (nps[j] - nb[j])\n",
    "            # vp[i,j] /= (ns[i] * ns[j])\n",
    "            vp[i,j] = vp[i,j] / (ns[i] * ns[j]) if ns[i] * ns[j] != 0 else vp[i,j]\n",
    "\n",
    "    dt = datetime.datetime.now()\n",
    "    # np.savetxt(\"./misc/vr_metric\"+dt.strftime(\"%d--%H-%M-%S\")+\".dat\", vp+vp.T, fmt=\"%1.5f\")\n",
    "    np.savetxt(savepath+modelname+dt.strftime(\"%m-%d--%H-%M-%S\")+\".dat\", vp+vp.T, fmt=\"%1.5f\")\n",
    "    print(savepath+modelname+dt.strftime(\"%m-%d--%H-%M-%S\")+\".dat\")"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "61d7d72412218704c5ba1799d65c7a83b08e24a9ca7847de9a479f6f426633e7"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
